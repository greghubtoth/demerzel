{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f76eeb-84e8-4040-8238-7184ada85d60",
   "metadata": {},
   "source": [
    "# Master notebook\n",
    "Designed to run 3 \"children\" notebooks to execute:\n",
    "1. Supervised Fine Tuning (SFT)\n",
    "2. Generating AI feedback data\n",
    "3. Reward Modelling (RM) and Reinforcement Learning (RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea22bc3-11af-45a2-9af0-3d55b199ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absl-py-2.1.0 accelerate-0.27.2 aiohttp-3.9.3 aiosignal-1.3.1 click-8.1.7 datasets-2.17.1 dill-0.3.8 entrypoints-0.4 evaluate-0.4.1 filelock-3.13.1 frozenlist-1.4.1 fsspec-2023.10.0 huggingface-hub-0.20.3 joblib-1.3.2 loralib-0.1.2 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 pandas-2.2.1 papermill-2.5.0 peft-0.8.2 pillow-10.2.0 pyarrow-15.0.0 pyarrow-hotfix-0.6 regex-2023.12.25 responses-0.18.0 rouge_score-0.1.2 safetensors-0.4.2 sympy-1.12 tenacity-8.2.3 tokenizers-0.15.2 torch-2.2.1 torchaudio-2.2.1 torchvision-0.17.1 tqdm-4.66.2 transformers-4.38.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9442958f-6bd4-4043-a2bb-d30413a4f718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (2.2.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: torchvision in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (0.17.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp39-cp39-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torchaudio in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (2.2.0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.2-cp39-cp39-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: transformers in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (4.36.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (2.11.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: evaluate in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (0.4.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: rouge_score in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: loralib in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (0.1.1)\n",
      "Collecting loralib\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: peft in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (0.7.1)\n",
      "Collecting peft\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: papermill in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/owner/.local/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: numpy in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: xxhash in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from datasets) (3.9.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: responses<0.19 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: absl-py in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: psutil in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from peft) (5.9.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from peft) (0.25.0)\n",
      "Requirement already satisfied: click in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (8.0.4)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (5.3.0)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (0.5.13)\n",
      "Requirement already satisfied: entrypoints in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (8.2.3)\n",
      "Requirement already satisfied: ansicolors in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from papermill) (1.1.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: traitlets>=5.0.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbclient>=0.2.0->papermill) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbclient>=0.2.0->papermill) (7.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbclient>=0.2.0->papermill) (1.5.5)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbformat>=5.2.0->papermill) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbformat>=5.2.0->papermill) (4.10.0)\n",
      "Requirement already satisfied: fastjsonschema in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nbformat>=5.2.0->papermill) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: joblib in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.18.0)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.0 in /Users/owner/opt/anaconda3/envs/nlp-intro/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient>=0.2.0->papermill) (6.1)\n",
      "Downloading torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp39-cp39-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.2.2-cp39-cp39-macosx_10_13_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp39-cp39-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: loralib, torch, huggingface-hub, torchvision, torchaudio, tokenizers, transformers, datasets, peft, evaluate\n",
      "  Attempting uninstall: loralib\n",
      "    Found existing installation: loralib 0.1.1\n",
      "    Uninstalling loralib-0.1.1:\n",
      "      Successfully uninstalled loralib-0.1.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.4\n",
      "    Uninstalling huggingface-hub-0.19.4:\n",
      "      Successfully uninstalled huggingface-hub-0.19.4\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.0\n",
      "    Uninstalling torchvision-0.17.0:\n",
      "      Successfully uninstalled torchvision-0.17.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.2.0\n",
      "    Uninstalling torchaudio-2.2.0:\n",
      "      Successfully uninstalled torchaudio-2.2.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Uninstalling tokenizers-0.15.0:\n",
      "      Successfully uninstalled tokenizers-0.15.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.11.0\n",
      "    Uninstalling datasets-2.11.0:\n",
      "      Successfully uninstalled datasets-2.11.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.7.1\n",
      "    Uninstalling peft-0.7.1:\n",
      "      Successfully uninstalled peft-0.7.1\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.0\n",
      "    Uninstalling evaluate-0.4.0:\n",
      "      Successfully uninstalled evaluate-0.4.0\n",
      "Successfully installed datasets-2.19.0 evaluate-0.4.1 huggingface-hub-0.22.2 loralib-0.1.2 peft-0.10.0 tokenizers-0.19.1 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2 transformers-4.40.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio transformers datasets evaluate rouge_score loralib peft papermill -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f80167-fe96-44d4-b526-85be243f523e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/owner/PycharmProjects/ai-msc-dissertation/notebooks\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import uuid\n",
    "import papermill as pm\n",
    "import pathlib\n",
    "from nyx.constants import COMMON_OUTPUT_PATHS\n",
    "\n",
    "cwd = pathlib.Path().resolve()\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb2c51-71aa-4fde-98bf-6dcf3a721761",
   "metadata": {},
   "source": [
    "# Note!\n",
    "Setting the DEVICE parameter detemerines what resource the model will be trained on, e.g., CPU, GPU or ARM architecture GPU referred to as MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540da2a0-d119-4f26-b34e-5860d290c7a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/705e5ac9f4464aed9df57f70a6287c3b\n"
     ]
    }
   ],
   "source": [
    "### run parameters\n",
    "\n",
    "PRECISION_NAME = 'float32'\n",
    "DEVICE = \"mps\"  # 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Inputting small models for testing efficiency.\n",
    "CHOSEN_MODEL = \"bigscience/mt0-small\"  # \"bigscience/mt0-base\"\n",
    "LABELLER_MODEL = \"bigscience/mt0-small\"  # \"google/flan-t5-large\"\n",
    "TESTING = True\n",
    "RANDOM_SEED = 42\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "common_path = COMMON_OUTPUT_PATHS.format(RUN_ID=RUN_ID)\n",
    "print(common_path)\n",
    "sft_notebook_config = {\n",
    "    'PRECISION_NAME': PRECISION_NAME,\n",
    "    'DEVICE': DEVICE,\n",
    "    'CHOSEN_MODEL': CHOSEN_MODEL,\n",
    "    'TESTING': TESTING,\n",
    "    'RUN_ID': RUN_ID,\n",
    "}\n",
    "\n",
    "labelling_notebook_config = {\n",
    "    'PRECISION_NAME': PRECISION_NAME,\n",
    "    'DEVICE': DEVICE,\n",
    "    'LABELLER_MODEL': LABELLER_MODEL,\n",
    "    'TESTING': TESTING,\n",
    "    'RUN_ID': RUN_ID,\n",
    "    'RANDOM_SEED': RANDOM_SEED,\n",
    "}\n",
    "\n",
    "rlhf_notebook_config = {\n",
    "    'PRECISION_NAME': PRECISION_NAME,\n",
    "    'DEVICE': DEVICE,\n",
    "    'CHOSEN_MODEL': CHOSEN_MODEL,\n",
    "    'TESTING': TESTING,\n",
    "    'RUN_ID': RUN_ID,\n",
    "    'RANDOM_SEED': RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845d8ffe-1914-4ed2-a621-57afd53b7373",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function execute_notebook in module papermill.execute:\n",
      "\n",
      "execute_notebook(input_path, output_path, parameters=None, engine_name=None, request_save_on_cell_execute=True, prepare_only=False, kernel_name=None, language=None, progress_bar=True, log_output=False, stdout_file=None, stderr_file=None, start_timeout=60, report_mode=False, cwd=None, **engine_kwargs)\n",
      "    Executes a single notebook locally.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    input_path : str or Path or nbformat.NotebookNode\n",
      "        Path to input notebook or NotebookNode object of notebook\n",
      "    output_path : str or Path or None\n",
      "        Path to save executed notebook. If None, no file will be saved\n",
      "    parameters : dict, optional\n",
      "        Arbitrary keyword arguments to pass to the notebook parameters\n",
      "    engine_name : str, optional\n",
      "        Name of execution engine to use\n",
      "    request_save_on_cell_execute : bool, optional\n",
      "        Request save notebook after each cell execution\n",
      "    autosave_cell_every : int, optional\n",
      "        How often in seconds to save in the middle of long cell executions\n",
      "    prepare_only : bool, optional\n",
      "        Flag to determine if execution should occur or not\n",
      "    kernel_name : str, optional\n",
      "        Name of kernel to execute the notebook against\n",
      "    language : str, optional\n",
      "        Programming language of the notebook\n",
      "    progress_bar : bool, optional\n",
      "        Flag for whether or not to show the progress bar.\n",
      "    log_output : bool, optional\n",
      "        Flag for whether or not to write notebook output to the configured logger\n",
      "    start_timeout : int, optional\n",
      "        Duration in seconds to wait for kernel start-up\n",
      "    report_mode : bool, optional\n",
      "        Flag for whether or not to hide input.\n",
      "    cwd : str or Path, optional\n",
      "        Working directory to use when executing the notebook\n",
      "    **kwargs\n",
      "        Arbitrary keyword arguments to pass to the notebook engine\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    nb : NotebookNode\n",
      "       Executed notebook object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pm.execute_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21ed2d5-919f-4f68-bfea-d5749f9bfe82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passed unknown parameter: PRECISION_NAME\n",
      "Passed unknown parameter: DEVICE\n",
      "Passed unknown parameter: CHOSEN_MODEL\n",
      "Passed unknown parameter: TESTING\n",
      "Input notebook does not contain a cell with tag 'parameters'\n",
      "Executing:  87%|█████████████████████████████████████████████████████████████████████████████████████████▋             | 27/31 [03:07<00:41, 10.47s/cell]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Executing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [03:15<00:00,  6.30s/cell]\n",
      "Passed unknown parameter: PRECISION_NAME\n",
      "Passed unknown parameter: DEVICE\n",
      "Passed unknown parameter: LABELLER_MODEL\n",
      "Passed unknown parameter: TESTING\n",
      "Passed unknown parameter: RANDOM_SEED\n",
      "Input notebook does not contain a cell with tag 'parameters'\n",
      "Executing: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [1:19:26<00:00, 176.54s/cell]\n",
      "Passed unknown parameter: PRECISION_NAME\n",
      "Passed unknown parameter: DEVICE\n",
      "Passed unknown parameter: CHOSEN_MODEL\n",
      "Passed unknown parameter: TESTING\n",
      "Passed unknown parameter: RANDOM_SEED\n",
      "Input notebook does not contain a cell with tag 'parameters'\n",
      "Executing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [06:43<00:00, 10.62s/cell]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cells': [{'id': '90995387',\n",
       "   'cell_type': 'code',\n",
       "   'metadata': {'tags': ['injected-parameters'],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:24.802051',\n",
       "     'end_time': '2024-02-23T23:02:24.847721',\n",
       "     'duration': 0.04567,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:24.814453Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:24.814901Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:24.846427Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:24.845254Z'}},\n",
       "   'execution_count': 1,\n",
       "   'source': '# Parameters\\nPRECISION_NAME = \"float32\"\\nDEVICE = \"mps\"\\nCHOSEN_MODEL = \"bigscience/mt0-small\"\\nTESTING = True\\nRANDOM_SEED = 42\\n',\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '02d7ae29-e41c-42ad-a5ce-ded3227265e9',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:24.851065',\n",
       "     'end_time': '2024-02-23T23:02:24.853866',\n",
       "     'duration': 0.002801,\n",
       "     'status': 'completed'}},\n",
       "   'source': '#\\xa0RLHF'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '3c07a6ad-f8ec-4eac-94e4-49b0ff69eca0',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:24.856066',\n",
       "     'end_time': '2024-02-23T23:02:24.858151',\n",
       "     'duration': 0.002085,\n",
       "     'status': 'completed'}},\n",
       "   'source': '## Reward Modelling\\n\\n### Data preparation\\nEncoder-Decoder specific line 54<br>\\nSampling from a range of start and end prompts could help robustness in the RM model.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 2,\n",
       "   'id': 'bcc63bef-276f-4c17-bb08-7ef664137a12',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:24.860903',\n",
       "     'end_time': '2024-02-23T23:02:31.477617',\n",
       "     'duration': 6.616714,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:24.863920Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:24.864105Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:31.476303Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:31.475924Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\\n  _torch_pytree._register_pytree_node(\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\\n  _torch_pytree._register_pytree_node(\\n'}],\n",
       "   'source': 'import time\\nimport torch\\nfrom peft import LoraConfig, TaskType, get_peft_model\\nfrom trl import RewardConfig, RewardTrainer\\nfrom peft import PeftModel\\nfrom typing import List\\nimport numpy as np\\n\\nfrom transformers import AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer, GenerationConfig, pipeline\\nfrom datasets import Dataset, concatenate_datasets, load_dataset, load_from_disk\\n\\nfrom trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\\nfrom trl import create_reference_model\\nfrom trl.core import LengthSampler\\n\\nfrom tqdm import tqdm\\n\\nTESTING = True\\n# PRECISION = torch.float32\\nPRECISION_NAME = \\'float32\\'\\nDEVICE = \"mps\"\\nCHOSEN_MODEL = \"google/flan-t5-large\"  # \"bigscience/mt0-small\"\\nRANDOM_SEED = 42\\n\\nCOMMON_MODELS_PATH = f\"./models/openai-subreddit-data/{CHOSEN_MODEL}\"\\nSFT_PEFT_MERGED_MODEL_PATH = f\"{COMMON_MODELS_PATH}/supervised-fine-tuning/merged-with-peft-adapter\"\\nSFT_PEFT_ADAPTER_PATH = f\"{COMMON_MODELS_PATH}/supervised-fine-tuning/peft-dialogue-summary-checkpoint-local\"\\n\\nSFT_DATA_OUTPUT_PATH = f\"./data/filtered_reddit_summarisation_data\"\\nCOMPARISON_DATA_PATH = \"./data/restructured_openai_comparison_data\"\\nRM_TRAIN_DATA_INPUT_PATH = \"./data/labelled_train_data\"\\n'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'id': '104a2bd6-d01c-42d1-ae6e-cf57d485c161',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:31.480648',\n",
       "     'end_time': '2024-02-23T23:02:31.490398',\n",
       "     'duration': 0.00975,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:31.483824Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:31.484258Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:31.489416Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:31.489083Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': 'torch.float32'},\n",
       "     'execution_count': 3}],\n",
       "   'source': 'from enum import Enum\\n\\ndef PrecisionEnumerator(requested_precision: str) -> torch.dtype:\\n    \"\"\"Enumarator to overcome torch precision serialisation issue.\\n    Google whether this can be replaced by a torch enum.\\n    \"\"\"\\n    if requested_precision == \\'float32\\': return torch.float32\\n    if requested_precision == \\'float16\\': return torch.float16\\n    if requested_precision == \\'bfloat16\\': return torch.bfloat16\\n    if requested_precision == \\'int8\\': return torch.int8\\n    \\ntype(PrecisionEnumerator(\\'float32\\'))\\n# type(torch.float32)\\n\\nPRECISION = PrecisionEnumerator(PRECISION_NAME)\\nPRECISION'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 4,\n",
       "   'id': '09e31f5e-03bf-4d20-99d9-6aea47ac01b5',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:31.493058',\n",
       "     'end_time': '2024-02-23T23:02:31.499631',\n",
       "     'duration': 0.006573,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:31.496122Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:31.496361Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:31.498736Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:31.498446Z'}},\n",
       "   'outputs': [],\n",
       "   'source': 'def print_number_of_trainable_model_parameters(model):\\n    trainable_model_params = 0\\n    all_model_params = 0\\n    for _, param in model.named_parameters():\\n        all_model_params += param.numel()\\n        if param.requires_grad:\\n            trainable_model_params += param.numel()\\n    return f\"trainable model parameters: {trainable_model_params}\\\\nall model parameters: {all_model_params}\\\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '1cc63b85-1e21-42d8-873f-7eab599bb773',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:31.501874',\n",
       "     'end_time': '2024-02-23T23:02:31.504234',\n",
       "     'duration': 0.00236,\n",
       "     'status': 'completed'}},\n",
       "   'source': '### Load model and data'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 5,\n",
       "   'id': '55837b16-932f-4a7e-b2c0-4996fc17c991',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:31.506450',\n",
       "     'end_time': '2024-02-23T23:02:31.524862',\n",
       "     'duration': 0.018412,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:31.509313Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:31.509485Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:31.523986Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:31.523670Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2'],\\n        num_rows: 20\\n    })\\n    validation: Dataset({\\n        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2'],\\n        num_rows: 18\\n    })\\n})\"},\n",
       "     'execution_count': 5}],\n",
       "   'source': '# Original dataset with train, test and validation\\ncomparison_dataset = load_from_disk(COMPARISON_DATA_PATH)\\n\\n# Train dataset with generated AI labels\\ncomparison_train_dataset = load_from_disk(RM_TRAIN_DATA_INPUT_PATH)\\n\\nif TESTING is True:\\n    comparison_dataset = comparison_dataset.filter(\\n        lambda example, index: index % 4680 == 0, with_indices=True\\n    )\\ncomparison_dataset'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 6,\n",
       "   'id': '26897fad-3569-4c97-b272-7974f4cdf771',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:31.527307',\n",
       "     'end_time': '2024-02-23T23:02:35.839119',\n",
       "     'duration': 4.311812,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:31.530871Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:31.531019Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:35.838083Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:35.837701Z'}},\n",
       "   'outputs': [{'output_type': 'stream', 'name': 'stdout', 'text': 'ok\\n'}],\n",
       "   'source': 'sft_model = AutoModelForSeq2SeqLM.from_pretrained(\\n    SFT_PEFT_MERGED_MODEL_PATH, torch_dtype=PRECISION\\n)\\n\\ntokenizer = AutoTokenizer.from_pretrained(CHOSEN_MODEL, model_max_length=512)\\n\\nsft_model.to(torch.device(DEVICE))\\nprint(\"ok\")'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 7,\n",
       "   'id': 'eb6405eb-8647-4a90-8213-7ffdd6d8f87b',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:35.841814',\n",
       "     'end_time': '2024-02-23T23:02:35.854003',\n",
       "     'duration': 0.012189,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:35.845129Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:35.845416Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:35.852457Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:35.851971Z'}},\n",
       "   'outputs': [],\n",
       "   'source': 'def create_summary_cols(example):\\n    start_prompt = \"Summarize the following reddit post.\\\\n\\\\n\"\\n    end_prompt = \"\\\\n\\\\nSummary: \"\\n    example[\\'summary_prompts_1\\'] = start_prompt + example[\"post\"] + end_prompt + example[\"candidate_summary_1\"]\\n    example[\\'summary_prompts_2\\'] = start_prompt + example[\"post\"] + end_prompt + example[\"candidate_summary_2\"]\\n    return example\\n\\ncomparison_train_dataset = comparison_train_dataset.map(create_summary_cols)\\n\\n# tokenized_train_dataset[\\'train\\'][\\'summary_prompts_1\\'][0]\\n\\n\\ndef prepare_for_reward_modelling(example, hf_baseline: bool = False):\\n    choice_column = example[\"choice\"] if hf_baseline is True else example[\"ai_choice\"]\\n    # ai_choice is based on index choice 0 ==summary 1, choice 1 == summary 2\\n    example[\"accepted_summary\"] = (\\n        example[\\'summary_prompts_2\\']\\n        if choice_column == example[\"dummy_choice\"]\\n        else example[\\'summary_prompts_1\\']\\n    )\\n    example[\"rejected_summary\"] = (\\n        example[\\'summary_prompts_1\\']\\n        if choice_column == example[\"dummy_choice\"]\\n        else example[\\'summary_prompts_2\\']\\n    )\\n    return example\\n\\n\\ncomparison_train_dataset = comparison_train_dataset.map(prepare_for_reward_modelling)'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 8,\n",
       "   'id': '4680a11f-6ba4-4f7b-9088-b2dee2611d1c',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:35.856360',\n",
       "     'end_time': '2024-02-23T23:02:35.864003',\n",
       "     'duration': 0.007643,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:35.859575Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:35.859764Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:35.862797Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:35.862293Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2', 'prompts', 'ai_choice', 'is_match', 'dummy_choice', 'summary_prompts_1', 'summary_prompts_2', 'accepted_summary', 'rejected_summary'],\\n        num_rows: 20\\n    })\\n})\"},\n",
       "     'execution_count': 8}],\n",
       "   'source': 'comparison_train_dataset'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 9,\n",
       "   'id': '10614346-71ce-4aee-be5b-4a7cf693c573',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:36.095747',\n",
       "     'end_time': '2024-02-23T23:02:48.484934',\n",
       "     'duration': 12.389187,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:36.098784Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:36.099139Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:48.484016Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:48.483647Z'}},\n",
       "   'outputs': [{'output_type': 'display_data',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': 'Map:   0%|          | 0/20 [00:00<?, ? examples/s]',\n",
       "      'application/vnd.jupyter.widget-view+json': {'version_major': 2,\n",
       "       'version_minor': 0,\n",
       "       'model_id': '75908458424740a1af33a5e26e288722'}}},\n",
       "    {'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected', 'labels', 'decoder_input_ids'],\\n        num_rows: 20\\n    })\\n})\"},\n",
       "     'execution_count': 9}],\n",
       "   'source': 'def tokenize_function(example):\\n    # start_prompt = \"Summarize the following reddit post.\\\\n\\\\n\"\\n    # end_prompt = \"\\\\n\\\\nSummary: \"\\n    # prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"post\"]]\\n    accepted = tokenizer(\\n        example[\"accepted_summary\"],\\n        padding=\"max_length\",\\n        truncation=True,\\n        return_tensors=\"pt\",\\n    ).to(torch.device(DEVICE))\\n    example[\"input_ids_chosen\"] = accepted.input_ids\\n    example[\"attention_mask_chosen\"] = accepted.attention_mask\\n    rejected = tokenizer(\\n        example[\"rejected_summary\"],\\n        padding=\"max_length\",\\n        truncation=True,\\n        return_tensors=\"pt\",\\n    ).to(torch.device(DEVICE))\\n    example[\"input_ids_rejected\"] = rejected.input_ids\\n    example[\"attention_mask_rejected\"] = rejected.attention_mask\\n\\n    example[\"labels\"] = tokenizer(\\n        [str(choice) for choice in example[\"ai_choice\"]],\\n        padding=\"max_length\",\\n        truncation=True,\\n        return_tensors=\"pt\",\\n    ).input_ids.to(torch.device(DEVICE))\\n    \\n    example[\"decoder_input_ids\"] = sft_model._shift_right(example[\"labels\"])\\n    return example\\n\\n\\nreward_modelling_train_dataset = comparison_train_dataset.map(tokenize_function, batched=True)\\nreward_modelling_train_dataset = reward_modelling_train_dataset.remove_columns(\\n    [\\'subreddit\\', \\'post\\', \\'choice\\', \\'candidate_summary_1\\', \\'candidate_summary_2\\', \\'prompts\\', \\'ai_choice\\', \\'is_match\\', \\'dummy_choice\\', \\n     \\'accepted_summary\\', \\'rejected_summary\\', \\'summary_prompts_2\\', \\'summary_prompts_1\\']\\n)\\nreward_modelling_train_dataset'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'aa5a0abd-4616-4465-942b-677aad7487b5',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:48.487865',\n",
       "     'end_time': '2024-02-23T23:02:48.490422',\n",
       "     'duration': 0.002557,\n",
       "     'status': 'completed'}},\n",
       "   'source': 'The below model is the pretrained SFT model with an additional head for classification.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 10,\n",
       "   'id': 'afbbbf3b-53e2-41d5-88c5-736aa3dff749',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:48.492790',\n",
       "     'end_time': '2024-02-23T23:02:50.508615',\n",
       "     'duration': 2.015825,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:48.495822Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:48.495978Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:50.507386Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:50.506966Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': \"Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at ./models/openai-subreddit-data/google/flan-t5-large/supervised-fine-tuning/merged-with-peft-adapter and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.dense.weight', 'classification_head.out_proj.weight', 'classification_head.dense.bias']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\n\"},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': \"'NoneType' object has no attribute 'cadam32bit_grad_fp32'\\ntrainable model parameters: 2383888\\nall model parameters: 753686546\\npercentage of trainable model parameters: 0.32%\\n\"},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\\n  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\\n'}],\n",
       "   'source': 'base_reward_model = AutoModelForSequenceClassification.from_pretrained(SFT_PEFT_MERGED_MODEL_PATH, torch_dtype=PRECISION)\\nbase_reward_model\\n\\nlora_config = LoraConfig(\\n    r=8,  # Determines the size of LoRA matrices. x*r * r*y = x*y\\n    lora_alpha=24,  # Scaling coefficient. LORA paper mentions it is important because the adjustments are small compared\\n    # to the rest of the model.\\n    target_modules=[\"q\", \"v\", \"dense\", \"out_proj\"], # The parameters / layers of the new head need to be enabled for training.\\n    lora_dropout=0.05,\\n    bias=\"none\",\\n    task_type=TaskType.SEQ_2_SEQ_LM,\\n)\\n\\nrm_peft_model = get_peft_model(base_reward_model, lora_config)\\nprint(print_number_of_trainable_model_parameters(rm_peft_model))'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 11,\n",
       "   'id': 'ea0b1db0-0070-46c2-a48a-0f5c6b0ec118',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:50.511713',\n",
       "     'end_time': '2024-02-23T23:02:50.518982',\n",
       "     'duration': 0.007269,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:50.514995Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:50.515143Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:50.517942Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:50.517569Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"Dataset({\\n    features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected', 'labels', 'decoder_input_ids'],\\n    num_rows: 20\\n})\"},\n",
       "     'execution_count': 11}],\n",
       "   'source': \"reward_modelling_train_dataset['train']\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 12,\n",
       "   'id': '46e025ce-3743-4588-8b0d-0794610a9dd7',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:50.521605',\n",
       "     'end_time': '2024-02-23T23:02:51.138425',\n",
       "     'duration': 0.61682,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:50.524688Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:50.524839Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:02:51.137336Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:02:51.136987Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:170: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\\n  warnings.warn(\\n/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:187: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\\n  warnings.warn(\\n'}],\n",
       "   'source': 'rm_output_dir = f\"{COMMON_MODELS_PATH}/reward_modelling/-{str(int(time.time()))}\"\\nrm_peft_model_path = f\"{COMMON_MODELS_PATH}/reward_modelling/peft-checkpoint-local\"\\n\\ntraining_args = RewardConfig(\\n    output_dir=rm_output_dir,\\n    # auto_find_batch_size=True,\\n    per_device_train_batch_size=2,\\n    save_steps=10_000,\\n    learning_rate=1e-3,  # Higher learning rate than full fine-tuning.    \\n    # num_train_epochs=3,\\n    logging_steps=1,\\n    max_steps=len(reward_modelling_train_dataset[\\'train\\']), \\n)\\n\\nreward_trainer = RewardTrainer(  # trainer class child\\n    model=rm_peft_model,\\n    args=training_args,  # trainerarguments child\\n    tokenizer=tokenizer,\\n    train_dataset=reward_modelling_train_dataset[\\'train\\'],\\n    # num_labels=1, # Regression\\n)\\n\\n# for _, param in peft_model.named_parameters():\\n#         # all_model_params += param.numel()\\n#         param.requires_grad = True\\n# print(print_number_of_trainable_model_parameters(peft_model))'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 13,\n",
       "   'id': '2675f352-0772-4c39-921c-d18f123853dd',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:02:51.141551',\n",
       "     'end_time': '2024-02-23T23:03:20.197608',\n",
       "     'duration': 29.056057,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:02:51.144596Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:02:51.144873Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:20.196571Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:20.196170Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': \"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\\n\"},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': \"/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2636: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\\n  warnings.warn(\\n\"},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\\n  warnings.warn(\\n/Users/gtoth/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\\n  warnings.warn(\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': 'Could not estimate the number of tokens of the input, floating-point operations will not be computed\\n'},\n",
       "    {'output_type': 'display_data',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': '<IPython.core.display.HTML object>',\n",
       "      'text/html': '\\n    <div>\\n      \\n      <progress value=\\'20\\' max=\\'20\\' style=\\'width:300px; height:20px; vertical-align: middle;\\'></progress>\\n      [20/20 00:20, Epoch 2/2]\\n    </div>\\n    <table border=\"1\" class=\"dataframe\">\\n  <thead>\\n <tr style=\"text-align: left;\">\\n      <th>Step</th>\\n      <th>Training Loss</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <td>1</td>\\n      <td>0.715500</td>\\n    </tr>\\n    <tr>\\n      <td>2</td>\\n      <td>0.699100</td>\\n    </tr>\\n    <tr>\\n      <td>3</td>\\n      <td>0.661600</td>\\n    </tr>\\n    <tr>\\n      <td>4</td>\\n      <td>0.606300</td>\\n    </tr>\\n    <tr>\\n      <td>5</td>\\n      <td>0.801900</td>\\n    </tr>\\n    <tr>\\n      <td>6</td>\\n      <td>0.704600</td>\\n    </tr>\\n    <tr>\\n      <td>7</td>\\n      <td>0.678400</td>\\n    </tr>\\n    <tr>\\n      <td>8</td>\\n      <td>0.749100</td>\\n    </tr>\\n    <tr>\\n      <td>9</td>\\n      <td>0.685100</td>\\n    </tr>\\n    <tr>\\n      <td>10</td>\\n      <td>0.735300</td>\\n    </tr>\\n    <tr>\\n      <td>11</td>\\n      <td>0.714700</td>\\n    </tr>\\n    <tr>\\n      <td>12</td>\\n      <td>0.880600</td>\\n    </tr>\\n    <tr>\\n      <td>13</td>\\n      <td>0.570200</td>\\n    </tr>\\n    <tr>\\n      <td>14</td>\\n      <td>0.722200</td>\\n    </tr>\\n    <tr>\\n      <td>15</td>\\n      <td>0.753300</td>\\n    </tr>\\n    <tr>\\n      <td>16</td>\\n      <td>0.662900</td>\\n    </tr>\\n    <tr>\\n      <td>17</td>\\n      <td>0.744400</td>\\n    </tr>\\n    <tr>\\n      <td>18</td>\\n      <td>0.713800</td>\\n    </tr>\\n    <tr>\\n      <td>19</td>\\n      <td>0.707400</td>\\n    </tr>\\n    <tr>\\n      <td>20</td>\\n      <td>0.658800</td>\\n    </tr>\\n  </tbody>\\n</table><p>'}},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': '1708729400.120988\\nTraining for 1 epoch took 28.98 seconds to execute.\\n'},\n",
       "    {'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"('./models/openai-subreddit-data/google/flan-t5-large/reward_modelling/peft-checkpoint-local/tokenizer_config.json',\\n './models/openai-subreddit-data/google/flan-t5-large/reward_modelling/peft-checkpoint-local/special_tokens_map.json',\\n './models/openai-subreddit-data/google/flan-t5-large/reward_modelling/peft-checkpoint-local/tokenizer.json')\"},\n",
       "     'execution_count': 13}],\n",
       "   'source': 'start = time.time()\\n\\nreward_trainer.train()\\nend = time.time()\\n\\nduration = end - start\\nprint(end)\\nprint(f\"Training for 1 epoch took {round(duration, 2)} seconds to execute.\")\\n\\nreward_trainer.model.save_pretrained(rm_peft_model_path)\\ntokenizer.save_pretrained(rm_peft_model_path)'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '8e0958ff-a546-4a45-b658-c5a047c079d5',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:20.200931',\n",
       "     'end_time': '2024-02-23T23:03:20.203951',\n",
       "     'duration': 0.00302,\n",
       "     'status': 'completed'}},\n",
       "   'source': '### Reload and evaluate RM model'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'bb8e2b55-4b46-4dc6-9336-9f9c07592a08',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:20.206691',\n",
       "     'end_time': '2024-02-23T23:03:20.209703',\n",
       "     'duration': 0.003012,\n",
       "     'status': 'completed'}},\n",
       "   'source': '### Merge and save RM model (with base model)\\nSo that, the sentiment pipe warning is eliminated.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 14,\n",
       "   'id': 'da40dc71-09f9-485c-9aad-a289960ba6d7',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:20.212637',\n",
       "     'end_time': '2024-02-23T23:03:22.202093',\n",
       "     'duration': 1.989456,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:20.216390Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:20.216599Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:22.200975Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:22.200640Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# Merging and saving the model which is trained all the way (i.e., utilising all of the data).\\nmerged_peft_rm_model_path = f\"{COMMON_MODELS_PATH}/reward_modelling/merged-with-peft-adapter\"\\nmerged_rm_model = rm_peft_model.merge_and_unload()\\nmerged_rm_model.save_pretrained(merged_peft_rm_model_path)'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 15,\n",
       "   'id': 'a9db1ed0-72cc-40f4-8739-0de204a2c166',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:22.205168',\n",
       "     'end_time': '2024-02-23T23:03:22.211386',\n",
       "     'duration': 0.006218,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:22.208533Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:22.208661Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:22.210550Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:22.210253Z'}},\n",
       "   'outputs': [],\n",
       "   'source': \"### Loop this over [base, 500, 1000, 5000, 10_000, 50_000, 100_000] to calculate the pairwise accuracy\\n\\n\\n# peft_rm_model = PeftModel.from_pretrained(base_reward_model, \\n#                                        f'{rm_peft_model_path}', \\n#                                        torch_dtype=PRECISION,\\n#                                        is_trainable=False)\\n\\n# peft_rm_model.to(torch.device('mps'))\\n# print('PEFT trained RM is loaded.')\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 16,\n",
       "   'id': '7ae5d33d-6689-435e-a084-fbaa8b473cab',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:22.214167',\n",
       "     'end_time': '2024-02-23T23:03:22.220123',\n",
       "     'duration': 0.005956,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:22.217216Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:22.217346Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:22.219319Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:22.219037Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# sentiment_pipe = pipeline(\"sentiment-analysis\", \\n#                           model=peft_rm_model,\\n#                           tokenizer=tokenizer,\\n#                           device=DEVICE)\\n# reward_logits_kwargs = {\\n#     \"top_k\": None, # Return all scores.\\n#     \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\\n#     \"batch_size\": 2\\n# }\\n\\n# reward_probabilities_kwargs = {\\n#     \"top_k\": None, # Return all scores.\\n#     \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\\n#     \"batch_size\": 2\\n# }\\n# candidate_1 = comparison_dataset[\\'validation\\'][\\'candidate_summary_1\\'][0]\\n# candidate_2 = comparison_dataset[\\'validation\\'][\\'candidate_summary_2\\'][0]\\n\\n# print(\"Reward model output:\")\\n# print(\"For candidate_1 text\")\\n# print(sentiment_pipe([candidate_1, candidate_2], **reward_logits_kwargs))\\n# print(sentiment_pipe([candidate_1, candidate_2], **reward_probabilities_kwargs))\\n# print(\"For candidate_2 text\")\\n# print(sentiment_pipe(candidate_2, **reward_logits_kwargs))\\n# print(sentiment_pipe(candidate_2, **reward_probabilities_kwargs))'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '0b5e71a9-55a7-473c-8bd4-2470cbfc68b2',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:22.223102',\n",
       "     'end_time': '2024-02-23T23:03:22.226029',\n",
       "     'duration': 0.002927,\n",
       "     'status': 'completed'}},\n",
       "   'source': '### _Comparing HF and AIF data (RM model generated)_\\nUtilising the train test split function to select a random 15% of the validation set to compare HF and AIF labels.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 17,\n",
       "   'id': '25280a3c-3f3d-4386-853f-ef811f5f022a',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:22.228624',\n",
       "     'end_time': '2024-02-23T23:03:26.000084',\n",
       "     'duration': 3.77146,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:22.231911Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:22.232060Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:25.995018Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:25.996118Z'}},\n",
       "   'outputs': [{'output_type': 'stream', 'name': 'stdout', 'text': '3\\n'}],\n",
       "   'source': 'rm_eval_data = comparison_dataset[\\'validation\\'].train_test_split(test_size=0.15, seed=RANDOM_SEED)\\nrm_eval_data[\\'test\\']\\nprint(len(rm_eval_data[\\'test\\']))\\ndef get_rm_probabilities(col: str, rm_model_to_evaluate = merged_rm_model) -> List[List[str]]:\\n    candidate = rm_model_to_evaluate(tokenizer(rm_eval_data[\\'test\\'][col],\\n                           padding=\"max_length\",\\n            truncation=True,\\n            return_tensors=\"pt\",\\n        ).input_ids.to(DEVICE))\\n\\n\\n    candidate_probabilities = candidate.logits.softmax(dim=-1).tolist()\\n    return candidate_probabilities\\n\\ncandidate_1_probabilities = get_rm_probabilities(\\'candidate_summary_1\\')\\ncandidate_2_probabilities = get_rm_probabilities(\\'candidate_summary_2\\')'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 18,\n",
       "   'id': 'dcc60384-48ea-4608-a4c6-c412fe1c8a59',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.021367',\n",
       "     'end_time': '2024-02-23T23:03:26.050221',\n",
       "     'duration': 0.028854,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.025238Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.029664Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.049299Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.049010Z'}},\n",
       "   'outputs': [{'output_type': 'display_data',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': 'Map:   0%|          | 0/3 [00:00<?, ? examples/s]',\n",
       "      'application/vnd.jupyter.widget-view+json': {'version_major': 2,\n",
       "       'version_minor': 0,\n",
       "       'model_id': 'f458be8c4cb440e8a42acf6348180e84'}}},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'The Reward Model (RM) is in agreement with the annotator provided labels: 66.67% of the times.\\n'}],\n",
       "   'source': '# Taking the first item in probabilities will yield the probability of being a chosen summary.\\nrm_eval_data[\\'test\\'] = rm_eval_data[\\'test\\'].add_column(\\n    name=\"candidate_1_preference_probability\", column=[item[0] for item in candidate_1_probabilities]\\n)\\nrm_eval_data[\\'test\\'] = rm_eval_data[\\'test\\'].add_column(\\n    name=\"candidate_2_preference_probability\", column=[item[0] for item in candidate_2_probabilities]\\n)\\n\\ndef get_rm_labels(example):\\n    example[\"rm_choice\"] = 0 if example[\"candidate_1_preference_probability\"] >= example[\"candidate_2_preference_probability\"] else 1\\n    example[\"is_match\"] = 1 if example[\"choice\"] == example[\"rm_choice\"] else 0\\n    return example\\n\\n\\n# Apply the function to each example in the dataset\\nrm_eval_data[\\'test\\'] = rm_eval_data[\\'test\\'].map(get_rm_labels)\\n\\n# Calculate the mean value of the \\'is_match\\' feature\\nrm_aggreement_mean_value = np.round(np.mean(rm_eval_data[\\'test\\'][\"is_match\"]) * 100, 2)\\nprint(f\"The Reward Model (RM) is in agreement with the annotator provided labels: {rm_aggreement_mean_value}% of the times.\")'},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': 'bbd9c288-ad4f-49af-9915-417a9e1ef57f',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.053162',\n",
       "     'end_time': '2024-02-23T23:03:26.056183',\n",
       "     'duration': 0.003021,\n",
       "     'status': 'completed'}},\n",
       "   'source': '## Reinforcement Learning'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 19,\n",
       "   'id': 'fc4231f3-4225-421f-8f08-8985d2ec6b40',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.059202',\n",
       "     'end_time': '2024-02-23T23:03:26.101721',\n",
       "     'duration': 0.042519,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.062741Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.062899Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.100875Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.100552Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 116722\\n    })\\n    test: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 6553\\n    })\\n    validation: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 6447\\n    })\\n})\"},\n",
       "     'execution_count': 19}],\n",
       "   'source': 'dataset = load_from_disk(SFT_DATA_OUTPUT_PATH)\\ndataset'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 20,\n",
       "   'id': 'b1719748-0188-4a0a-badb-71f0ca54df36',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.104687',\n",
       "     'end_time': '2024-02-23T23:03:26.115472',\n",
       "     'duration': 0.010785,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.108305Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.108452Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.114604Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.114297Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 25\\n    })\\n    test: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 2\\n    })\\n    validation: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary'],\\n        num_rows: 2\\n    })\\n})\"},\n",
       "     'execution_count': 20}],\n",
       "   'source': 'if TESTING is True:\\n    dataset = dataset.filter(\\n        lambda example, index: index % 4680 == 0, with_indices=True\\n    )\\ndataset'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 21,\n",
       "   'id': '0249e3a2-1574-4afd-ae97-a61c042964a8',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.118721',\n",
       "     'end_time': '2024-02-23T23:03:26.259573',\n",
       "     'duration': 0.140852,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.122341Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.122477Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.258429Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.258052Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'trainable model parameters: 2359296\\nall model parameters: 785509376\\npercentage of trainable model parameters: 0.30%\\n'}],\n",
       "   'source': 'rl_lora_config = LoraConfig(\\n    r=8, # Rank\\n    lora_alpha=24,\\n    target_modules=[\"q\", \"v\"],\\n    lora_dropout=0.05,\\n    bias=\"none\",\\n    task_type=TaskType.SEQ_2_SEQ_LM\\n)\\n\\n\\nrl_peft_model = get_peft_model(sft_model, rl_lora_config)\\nprint(print_number_of_trainable_model_parameters(rl_peft_model))\\n'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 22,\n",
       "   'id': 'f8571a9c-4df0-45d8-8200-44976b8625b5',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.262784',\n",
       "     'end_time': '2024-02-23T23:03:26.291112',\n",
       "     'duration': 0.028328,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.266512Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.266661Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.290202Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.289838Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'PPO model has trainable model parameters: 2360321\\nall model parameters: 785510401\\npercentage of trainable model parameters: 0.30%\\n\\nAutoModelForSeq2SeqLMWithValueHead(\\n  (pretrained_model): PeftModelForSeq2SeqLM(\\n    (base_model): LoraModel(\\n      (model): T5ForConditionalGeneration(\\n        (shared): Embedding(32128, 1024)\\n        (encoder): T5Stack(\\n          (embed_tokens): Embedding(32128, 1024)\\n          (block): ModuleList(\\n            (0): T5Block(\\n              (layer): ModuleList(\\n                (0): T5LayerSelfAttention(\\n                  (SelfAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (relative_attention_bias): Embedding(32, 16)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (1): T5LayerFF(\\n                  (DenseReluDense): T5DenseGatedActDense(\\n                    (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wo): Linear(in_features=2816, out_features=1024, bias=False)\\n                    (dropout): Dropout(p=0.1, inplace=False)\\n                    (act): NewGELUActivation()\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n              )\\n            )\\n            (1-23): 23 x T5Block(\\n              (layer): ModuleList(\\n                (0): T5LayerSelfAttention(\\n                  (SelfAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (1): T5LayerFF(\\n                  (DenseReluDense): T5DenseGatedActDense(\\n                    (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wo): Linear(in_features=2816, out_features=1024, bias=False)\\n                    (dropout): Dropout(p=0.1, inplace=False)\\n                    (act): NewGELUActivation()\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n              )\\n            )\\n          )\\n          (final_layer_norm): T5LayerNorm()\\n          (dropout): Dropout(p=0.1, inplace=False)\\n        )\\n        (decoder): T5Stack(\\n          (embed_tokens): Embedding(32128, 1024)\\n          (block): ModuleList(\\n            (0): T5Block(\\n              (layer): ModuleList(\\n                (0): T5LayerSelfAttention(\\n                  (SelfAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (relative_attention_bias): Embedding(32, 16)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (1): T5LayerCrossAttention(\\n                  (EncDecAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (2): T5LayerFF(\\n                  (DenseReluDense): T5DenseGatedActDense(\\n                    (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wo): Linear(in_features=2816, out_features=1024, bias=False)\\n                    (dropout): Dropout(p=0.1, inplace=False)\\n                    (act): NewGELUActivation()\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n              )\\n            )\\n            (1-23): 23 x T5Block(\\n              (layer): ModuleList(\\n                (0): T5LayerSelfAttention(\\n                  (SelfAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (1): T5LayerCrossAttention(\\n                  (EncDecAttention): T5Attention(\\n                    (q): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (k): Linear(in_features=1024, out_features=1024, bias=False)\\n                    (v): lora.Linear(\\n                      (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\\n                      (lora_dropout): ModuleDict(\\n                        (default): Dropout(p=0.05, inplace=False)\\n                      )\\n                      (lora_A): ModuleDict(\\n                        (default): Linear(in_features=1024, out_features=8, bias=False)\\n                      )\\n                      (lora_B): ModuleDict(\\n                        (default): Linear(in_features=8, out_features=1024, bias=False)\\n                      )\\n                      (lora_embedding_A): ParameterDict()\\n                      (lora_embedding_B): ParameterDict()\\n                    )\\n                    (o): Linear(in_features=1024, out_features=1024, bias=False)\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (2): T5LayerFF(\\n                  (DenseReluDense): T5DenseGatedActDense(\\n                    (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\\n                    (wo): Linear(in_features=2816, out_features=1024, bias=False)\\n                    (dropout): Dropout(p=0.1, inplace=False)\\n                    (act): NewGELUActivation()\\n                  )\\n                  (layer_norm): T5LayerNorm()\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n              )\\n            )\\n          )\\n          (final_layer_norm): T5LayerNorm()\\n          (dropout): Dropout(p=0.1, inplace=False)\\n        )\\n        (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\\n      )\\n    )\\n  )\\n  (v_head): ValueHead(\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (summary): Linear(in_features=1024, out_features=1, bias=True)\\n    (flatten): Flatten(start_dim=1, end_dim=-1)\\n  )\\n)\\n'}],\n",
       "   'source': \"# A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning\\nppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(rl_peft_model,                                                               \\n                                                               torch_dtype=PRECISION,\\n                                                               is_trainable=True)\\n\\nprint(f'PPO model has {print_number_of_trainable_model_parameters(ppo_model)}\\\\n')\\nprint(ppo_model)\"},\n",
       "  {'cell_type': 'markdown',\n",
       "   'id': '0e5f926a-88c4-47db-a9dd-5c742731ba31',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.299005',\n",
       "     'end_time': '2024-02-23T23:03:26.302277',\n",
       "     'duration': 0.003272,\n",
       "     'status': 'completed'}},\n",
       "   'source': 'The below function could also be adapted to sample from a variety of prompts to improve exploration and improve\\nrobustness.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 23,\n",
       "   'id': '159cfba9-435f-4afd-88a2-00a114fa956b',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.305363',\n",
       "     'end_time': '2024-02-23T23:03:26.328075',\n",
       "     'duration': 0.022712,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.309579Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.309806Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.327075Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.326726Z'}},\n",
       "   'outputs': [{'output_type': 'execute_result',\n",
       "     'metadata': {},\n",
       "     'data': {'text/plain': \"DatasetDict({\\n    train: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\\n        num_rows: 25\\n    })\\n    test: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\\n        num_rows: 2\\n    })\\n    validation: Dataset({\\n        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\\n        num_rows: 2\\n    })\\n})\"},\n",
       "     'execution_count': 23}],\n",
       "   'source': 'def tokenize_for_rl(sample):\\n    # Wrap each dialogue with the instruction.\\n    prompt = f\"\"\"\\nSummarize the following reddit post.\\n\\n{sample[\"post\"]}\\n\\nSummary:\\n\"\"\"\\n    sample[\"input_ids\"] = tokenizer.encode(prompt)\\n\\n    # Requirement for PPO library.\\n    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\\n    return sample\\n\\n# Tokenize each dialogue.\\ndataset = dataset.map(tokenize_for_rl, batched=False)\\ndataset.set_format(type=\"torch\")\\ndataset'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 24,\n",
       "   'id': 'ddc80b03-568d-4ea4-990c-8264e8142fc9',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.331470',\n",
       "     'end_time': '2024-02-23T23:03:26.452918',\n",
       "     'duration': 0.121448,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.335382Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.335543Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.451860Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.451469Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'Reference model parameters to be updated:\\ntrainable model parameters: 0\\nall model parameters: 785510401\\npercentage of trainable model parameters: 0.00%\\n\\n'}],\n",
       "   'source': \"ref_model = create_reference_model(ppo_model)\\n\\nprint(f'Reference model parameters to be updated:\\\\n{print_number_of_trainable_model_parameters(ref_model)}\\\\n')\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 25,\n",
       "   'id': 'c8a7ee22-9c33-40d1-af58-996b9e236ca0',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.456728',\n",
       "     'end_time': '2024-02-23T23:03:26.464548',\n",
       "     'duration': 0.00782,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.460851Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.461016Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.463706Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.463378Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': \"Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}, {'key1': 'value2', 'key2': 'value3', 'key3': 'value4'}]\\nCollator output: {'key1': ['value1', 'value2'], 'key2': ['value2', 'value3'], 'key3': ['value3', 'value4']}\\n\"}],\n",
       "   'source': 'def collator(data):\\n    return dict((key, [d[key] for d in data]) for key in data[0])\\n\\ntest_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}, {\"key1\": \"value2\", \"key2\": \"value3\", \"key3\": \"value4\"}]\\nprint(f\\'Collator input: {test_data}\\')\\nprint(f\\'Collator output: {collator(test_data)}\\')'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 26,\n",
       "   'id': 'b6826a3d-2c88-4011-af76-6ec5be7bea6d',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.468155',\n",
       "     'end_time': '2024-02-23T23:03:26.786462',\n",
       "     'duration': 0.318307,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.471981Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.472134Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.784994Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.784585Z'}},\n",
       "   'outputs': [],\n",
       "   'source': 'config = PPOConfig(\\n    # Name of model to use - used only for tracking purposes\\n    model_name=CHOSEN_MODEL,    \\n    learning_rate=1.41e-5,\\n    ppo_epochs=1,\\n    mini_batch_size=1,\\n    batch_size=2,\\n    # per_device_train_batch_size=2,\\n    # save_steps=5_000,\\n)\\n\\nppo_trainer = PPOTrainer(config=config, \\n                         model=ppo_model, \\n                         ref_model=ref_model, \\n                         tokenizer=tokenizer, \\n                         dataset=dataset[\"train\"], \\n                         data_collator=collator)'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 27,\n",
       "   'id': '70529ba8-fe82-40bb-82e6-c0bf19c42369',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.790810',\n",
       "     'end_time': '2024-02-23T23:03:26.801759',\n",
       "     'duration': 0.010949,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.795104Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.795256Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:03:26.800852Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:03:26.800542Z'}},\n",
       "   'outputs': [],\n",
       "   'source': 'sentiment_pipe = pipeline(\"sentiment-analysis\", \\n                          model=merged_rm_model,\\n                          tokenizer=tokenizer,\\n                          device=DEVICE)'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 28,\n",
       "   'id': '039d4017-d2a2-453f-9e83-b4fd7640a55e',\n",
       "   'metadata': {'scrolled': True,\n",
       "    'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:03:26.805191',\n",
       "     'end_time': '2024-02-23T23:09:03.964222',\n",
       "     'duration': 337.159031,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:03:26.809396Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:03:26.809548Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:09:03.921675Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:09:03.922171Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r0it [00:00, ?it/s]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r1it [01:05, 65.43s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'objective/kl: 0.0\\nppo/returns/mean: 0.029107429087162018\\nppo/policy/advantages_mean: 0.8348299264907837\\n---------------------------------------------------------------------------------------------------\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': 'Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r2it [01:36, 45.13s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'objective/kl: 0.001930125174112618\\nppo/returns/mean: -0.07996565103530884\\nppo/policy/advantages_mean: 0.19095686078071594\\n---------------------------------------------------------------------------------------------------\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r3it [02:03, 37.04s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'objective/kl: 0.002416378352791071\\nppo/returns/mean: 0.23973125219345093\\nppo/policy/advantages_mean: 0.1524638533592224\\n---------------------------------------------------------------------------------------------------\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r4it [04:56, 90.74s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'objective/kl: 0.005416803993284702\\nppo/returns/mean: 0.11598557978868484\\nppo/policy/advantages_mean: -0.01800353452563286\\n---------------------------------------------------------------------------------------------------\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r5it [05:37, 72.54s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stderr',\n",
       "     'text': '\\r5it [05:37, 67.42s/it]'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'objective/kl: 0.0067086368799209595\\nppo/returns/mean: 0.09573426097631454\\nppo/policy/advantages_mean: 0.1278599500656128\\n---------------------------------------------------------------------------------------------------\\n'},\n",
       "    {'output_type': 'stream', 'name': 'stderr', 'text': '\\n'}],\n",
       "   'source': 'output_min_length = 100\\noutput_max_length = 400\\noutput_length_sampler = LengthSampler(output_min_length, output_max_length)\\n\\npreferred_summary_index = 0\\n\\ngeneration_kwargs = {\\n    \"min_length\": 5,\\n    \"top_k\": 0.0,\\n    \"top_p\": 1.0,\\n    \"do_sample\": True\\n}\\n\\nreward_kwargs = {\\n    \"top_k\": None, # Return all scores.\\n    \"function_to_apply\": \"none\", # Raw logits without softmax.\\n    \"batch_size\": 2\\n}\\n\\nmax_ppo_steps = 5\\n\\nfor step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\\n    # Break when you reach max_steps.\\n    if step >= max_ppo_steps:\\n        break   \\n\\n    prompt_tensors = batch[\"input_ids\"]\\n\\n    # Get response from FLAN-T5/PEFT LLM.\\n    summary_tensors = []\\n\\n    for prompt_tensor in prompt_tensors:\\n        max_new_tokens = output_length_sampler()        \\n            \\n        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\\n        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\\n        \\n        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\\n        \\n    # This needs to be called \"response\".\\n    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\\n\\n    # Compute reward outputs.\\n    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \\n    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\\n\\n    # You use the `nothate` item because this is the score for the positive `nothate` class.\\n    reward_tensors = [torch.tensor(reward[preferred_summary_index][\"score\"]) for reward in rewards]    \\n\\n    # Run PPO step.\\n    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\\n    ppo_trainer.log_stats(stats, batch, reward_tensors)\\n    \\n    print(f\\'objective/kl: {stats[\"objective/kl\"]}\\')\\n    print(f\\'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}\\')\\n    print(f\\'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}\\')\\n    print(\\'-\\'.join(\\'\\' for x in range(100)))'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 29,\n",
       "   'id': '97bd898b-ff0f-4bfc-8825-670405f27e54',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-02-23T23:09:03.970994',\n",
       "     'end_time': '2024-02-23T23:09:03.980567',\n",
       "     'duration': 0.009573,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-02-23T23:09:03.976490Z',\n",
       "     'iopub.execute_input': '2024-02-23T23:09:03.976693Z',\n",
       "     'iopub.status.idle': '2024-02-23T23:09:03.979249Z',\n",
       "     'shell.execute_reply': '2024-02-23T23:09:03.978649Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# save the model each X step.\\n# compare before and after for each saved model.\\n#\\xa0plot the results.\\n\\n# Run new summarisation scripts through BIG LLM to evaluate.\\n# - cheap crowd sourced evaluation.'}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'tf-gpu',\n",
       "   'language': 'python',\n",
       "   'name': 'tf-gpu'},\n",
       "  'language_info': {'name': 'python',\n",
       "   'version': '3.10.9',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'file_extension': '.py'},\n",
       "  'papermill': {'default_parameters': {},\n",
       "   'parameters': {'PRECISION_NAME': 'float32',\n",
       "    'DEVICE': 'mps',\n",
       "    'CHOSEN_MODEL': 'bigscience/mt0-small',\n",
       "    'TESTING': True,\n",
       "    'RANDOM_SEED': 42},\n",
       "   'environment_variables': {},\n",
       "   'version': '2.5.0',\n",
       "   'input_path': '/Users/gtoth/Documents/AI_MSc/13.Dissertation/Experiments/03-reinforcement-learning-from-ai-or-human-feedback.ipynb',\n",
       "   'output_path': '/Users/gtoth/Documents/AI_MSc/13.Dissertation/Experiments/07-reinforcement-learning-from-ai-or-human-feedback.ipynb',\n",
       "   'start_time': '2024-02-23T23:02:23.482501',\n",
       "   'end_time': '2024-02-23T23:09:07.211346',\n",
       "   'duration': 403.728845,\n",
       "   'exception': None},\n",
       "  'widgets': {'application/vnd.jupyter.widget-state+json': {'state': {'3d59766d491c4b6db83f237b69e31ebf': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '76c2d44b90214d238d4916afcae8d3ef': {'model_name': 'ProgressStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'ProgressStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'bar_color': None,\n",
       "       'description_width': ''}},\n",
       "     '94442c12237a4303bbf2cc9fa62f09ad': {'model_name': 'FloatProgressModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'FloatProgressModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'ProgressView',\n",
       "       'bar_style': 'success',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_3d59766d491c4b6db83f237b69e31ebf',\n",
       "       'max': 20.0,\n",
       "       'min': 0.0,\n",
       "       'orientation': 'horizontal',\n",
       "       'style': 'IPY_MODEL_76c2d44b90214d238d4916afcae8d3ef',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': 20.0}},\n",
       "     '3139ba9bcc30443ba48525522d841cb5': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '63e779e65b004fc1b9ac594cede3d4ad': {'model_name': 'HTMLStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'background': None,\n",
       "       'description_width': '',\n",
       "       'font_size': None,\n",
       "       'text_color': None}},\n",
       "     'c7795f23c0f8454eb1dccc6e35dd9ad9': {'model_name': 'HTMLModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HTMLView',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_3139ba9bcc30443ba48525522d841cb5',\n",
       "       'placeholder': '\\u200b',\n",
       "       'style': 'IPY_MODEL_63e779e65b004fc1b9ac594cede3d4ad',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': 'Map: 100%'}},\n",
       "     '25235452b5974fe0b89685be5c78af8d': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     'd66c1dbf60094e62ae7ffc682d93df6e': {'model_name': 'HTMLStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'background': None,\n",
       "       'description_width': '',\n",
       "       'font_size': None,\n",
       "       'text_color': None}},\n",
       "     '9ba78b22eea84d5cb34ef7d351b6af23': {'model_name': 'HTMLModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HTMLView',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_25235452b5974fe0b89685be5c78af8d',\n",
       "       'placeholder': '\\u200b',\n",
       "       'style': 'IPY_MODEL_d66c1dbf60094e62ae7ffc682d93df6e',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': ' 20/20 [00:00&lt;00:00, 168.35 examples/s]'}},\n",
       "     '7817d45b6ff84604b0da68ffe41cd6a2': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '75908458424740a1af33a5e26e288722': {'model_name': 'HBoxModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HBoxModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HBoxView',\n",
       "       'box_style': '',\n",
       "       'children': ['IPY_MODEL_c7795f23c0f8454eb1dccc6e35dd9ad9',\n",
       "        'IPY_MODEL_94442c12237a4303bbf2cc9fa62f09ad',\n",
       "        'IPY_MODEL_9ba78b22eea84d5cb34ef7d351b6af23'],\n",
       "       'layout': 'IPY_MODEL_7817d45b6ff84604b0da68ffe41cd6a2',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None}},\n",
       "     '9971c05b03b34ecba8e7c2d3482a0b46': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '7f5831724438463a85354b12b84b95fe': {'model_name': 'ProgressStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'ProgressStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'bar_color': None,\n",
       "       'description_width': ''}},\n",
       "     '53d519bfe91d4c489272061bf26038ec': {'model_name': 'FloatProgressModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'FloatProgressModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'ProgressView',\n",
       "       'bar_style': 'success',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_9971c05b03b34ecba8e7c2d3482a0b46',\n",
       "       'max': 3.0,\n",
       "       'min': 0.0,\n",
       "       'orientation': 'horizontal',\n",
       "       'style': 'IPY_MODEL_7f5831724438463a85354b12b84b95fe',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': 3.0}},\n",
       "     'f47fc1eedbcd4fdc9f0f61b6beed4206': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '694ea8977179452985a118d09659f745': {'model_name': 'HTMLStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'background': None,\n",
       "       'description_width': '',\n",
       "       'font_size': None,\n",
       "       'text_color': None}},\n",
       "     '9aa97a1875714e59903ee73f8993e368': {'model_name': 'HTMLModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HTMLView',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_f47fc1eedbcd4fdc9f0f61b6beed4206',\n",
       "       'placeholder': '\\u200b',\n",
       "       'style': 'IPY_MODEL_694ea8977179452985a118d09659f745',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': 'Map: 100%'}},\n",
       "     '2b936946fd4b4956bcd541387dc3875a': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     '63b98efece474e218ce416f2775e1a40': {'model_name': 'HTMLStyleModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLStyleModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'StyleView',\n",
       "       'background': None,\n",
       "       'description_width': '',\n",
       "       'font_size': None,\n",
       "       'text_color': None}},\n",
       "     '5e1bbfcefde6407985cf266ffc735539': {'model_name': 'HTMLModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HTMLModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HTMLView',\n",
       "       'description': '',\n",
       "       'description_allow_html': False,\n",
       "       'layout': 'IPY_MODEL_2b936946fd4b4956bcd541387dc3875a',\n",
       "       'placeholder': '\\u200b',\n",
       "       'style': 'IPY_MODEL_63b98efece474e218ce416f2775e1a40',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None,\n",
       "       'value': ' 3/3 [00:00&lt;00:00, 401.34 examples/s]'}},\n",
       "     'bd77d18258dd40e3beba804d7605e396': {'model_name': 'LayoutModel',\n",
       "      'model_module': '@jupyter-widgets/base',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_model_module': '@jupyter-widgets/base',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'LayoutModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/base',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'LayoutView',\n",
       "       'align_content': None,\n",
       "       'align_items': None,\n",
       "       'align_self': None,\n",
       "       'border_bottom': None,\n",
       "       'border_left': None,\n",
       "       'border_right': None,\n",
       "       'border_top': None,\n",
       "       'bottom': None,\n",
       "       'display': None,\n",
       "       'flex': None,\n",
       "       'flex_flow': None,\n",
       "       'grid_area': None,\n",
       "       'grid_auto_columns': None,\n",
       "       'grid_auto_flow': None,\n",
       "       'grid_auto_rows': None,\n",
       "       'grid_column': None,\n",
       "       'grid_gap': None,\n",
       "       'grid_row': None,\n",
       "       'grid_template_areas': None,\n",
       "       'grid_template_columns': None,\n",
       "       'grid_template_rows': None,\n",
       "       'height': None,\n",
       "       'justify_content': None,\n",
       "       'justify_items': None,\n",
       "       'left': None,\n",
       "       'margin': None,\n",
       "       'max_height': None,\n",
       "       'max_width': None,\n",
       "       'min_height': None,\n",
       "       'min_width': None,\n",
       "       'object_fit': None,\n",
       "       'object_position': None,\n",
       "       'order': None,\n",
       "       'overflow': None,\n",
       "       'padding': None,\n",
       "       'right': None,\n",
       "       'top': None,\n",
       "       'visibility': None,\n",
       "       'width': None}},\n",
       "     'f458be8c4cb440e8a42acf6348180e84': {'model_name': 'HBoxModel',\n",
       "      'model_module': '@jupyter-widgets/controls',\n",
       "      'model_module_version': '2.0.0',\n",
       "      'state': {'_dom_classes': [],\n",
       "       '_model_module': '@jupyter-widgets/controls',\n",
       "       '_model_module_version': '2.0.0',\n",
       "       '_model_name': 'HBoxModel',\n",
       "       '_view_count': None,\n",
       "       '_view_module': '@jupyter-widgets/controls',\n",
       "       '_view_module_version': '2.0.0',\n",
       "       '_view_name': 'HBoxView',\n",
       "       'box_style': '',\n",
       "       'children': ['IPY_MODEL_9aa97a1875714e59903ee73f8993e368',\n",
       "        'IPY_MODEL_53d519bfe91d4c489272061bf26038ec',\n",
       "        'IPY_MODEL_5e1bbfcefde6407985cf266ffc735539'],\n",
       "       'layout': 'IPY_MODEL_bd77d18258dd40e3beba804d7605e396',\n",
       "       'tabbable': None,\n",
       "       'tooltip': None}}},\n",
       "    'version_major': 2,\n",
       "    'version_minor': 0}}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can write a function and for loop these notebook. Will be especially useful\n",
    "# when a new parameter manipulates the prompting style.\n",
    "\n",
    "# Notebook 1\n",
    "pm.execute_notebook(\n",
    "    input_path=f'{cwd}/01-sft-modelling-reddit-summarisation.ipynb',\n",
    "    output_path=f'{common_path}/notebooks/05-sft-modelling-reddit-summarisation.ipynb',\n",
    "    parameters=sft_notebook_config,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "## Notebook 2\n",
    "pm.execute_notebook(\n",
    "    input_path=f'{cwd}/02-ai-label-data-generation.ipynb',\n",
    "    output_path=f'{common_path}/notebooks/06-ai-label-data-generation.ipynb',\n",
    "    parameters=labelling_notebook_config,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "# Notebook 3\n",
    "pm.execute_notebook(\n",
    "    input_path=f'{cwd}/03-reinforcement-learning-from-ai-or-human-feedback.ipynb',\n",
    "    output_path=f'{common_path}/notebooks/07-reinforcement-learning-from-ai-or-human-feedback.ipynb',\n",
    "    parameters=rlhf_notebook_config,\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d65b7-e613-43be-9e5a-0b45e16fbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder -decoder related lines\n",
    "\n",
    "## Notebook 3\n",
    "# in tokenize_function()\n",
    "# command 7 line 29ish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a06552-48f9-4b2c-b778-21aa06183a8e",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "Test **prompt diversification technqiues**:\n",
    "- set up prompt changing in labeling\n",
    "- set up prompt sampling in RM prompting.\n",
    "  - try combinations of above.\n",
    "- set up critique revisions\n",
    "\n",
    "- try sampling thought and answers according to some criteria such as embedding etc. see miro.\n",
    "- try Tree of Thought and/or other.\n",
    "- look at papers chain of trees and chain of tables.\n",
    "\n",
    "Code changes:\n",
    "- implement above in notebooks 2 and 3 as appropriate.\n",
    "- in notebook 3 compute RM improvement w.r.t. to dataset used for training (utilise checkpoints).\n",
    "- track evaluation metrics per \"runId\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc72ada-73b6-43be-b322-6d339d2e72d5",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-diss",
   "language": "python",
   "name": "llm-diss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
