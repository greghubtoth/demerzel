{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d7ae29-e41c-42ad-a5ce-ded3227265e9",
   "metadata": {},
   "source": [
    "#Â RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07a6ad-f8ec-4eac-94e4-49b0ff69eca0",
   "metadata": {},
   "source": [
    "## Reward Modelling"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#!pip install peft trl weaviate-client",
   "id": "9cdd4eea259fe14f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc63bef-276f-4c17-bb08-7ef664137a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from trl import RewardConfig, RewardTrainer\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "TESTING = True\n",
    "\n",
    "PRECISION_NAME = 'float16'\n",
    "DEVICE = \"cuda\"\n",
    "CHOSEN_MODEL = \"microsoft/phi-1_5\"\n",
    "# \"microsoft/phi-1_5\" #\"bigscience/mt0-small\" # \"google/flan-t5-large\" \"stabilityai/stablelm-2-zephyr-1_6b\"\n",
    "RANDOM_SEED = 42\n",
    "RUN_ID = \"1ef0d64c95414628b7ddb35eb3bac2fe\"  # uuid.uuid4().hex  # '316a2787976e4e848ea635422e2ef684'\n",
    "\n",
    "LORA_PARAM_TARGET_MODULES = {\n",
    "    \"bigscience/mt0-small\": [\"q\", \"v\"],\n",
    "    \"microsoft/phi-1_5\": [\"q_proj\", \"v_proj\"],\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": [\"qkv_proj\"],\n",
    "    \"microsoft/Phi-3-medium-4k-instruct\": [\"qkv_proj\"],\n",
    "}\n",
    "\n",
    "RM_LORA_PARAM_R = 32\n",
    "RM_LORA_PARAM_ALPHA = 64\n",
    "RM_LORA_PARAM_TARGET_MODULES = LORA_PARAM_TARGET_MODULES[CHOSEN_MODEL] + [\n",
    "    \"dense\",\n",
    "    \"out_proj\",\n",
    "]\n",
    "RM_TRAIN_BATCH_SIZE = 5\n",
    "RM_LEARNING_RATE = 1e-5\n",
    "RM_TRAIN_DATA_RUN_ID = \"06d4cf76cc9c4b2aace1dd6d208bbc01\"\n",
    "\n",
    "RL_LORA_PARAM_R = 32\n",
    "RL_LORA_PARAM_ALPHA = 64\n",
    "RL_LORA_PARAM_TARGET_MODULES = LORA_PARAM_TARGET_MODULES[CHOSEN_MODEL]\n",
    "RL_TRAIN_BATCH_SIZE = 2\n",
    "RL_TRAIN_MINI_BATCH_SIZE = 1\n",
    "RL_LEARNING_RATE = 1.41e-7\n",
    "RL_N_EPOCHS = 1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path.cwd().parent.absolute()\n",
    "nyx_path = f'{path}/'\n",
    "print(nyx_path)\n",
    "sys.path.append(nyx_path)"
   ],
   "id": "35001d4a8ca68551"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104a2bd6-d01c-42d1-ae6e-cf57d485c161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nyx.evaluation import quantitative_comparison\n",
    "from nyx.data_generation.evaluators import AILabelEvaluator\n",
    "\n",
    "from nyx.utils import (\n",
    "    precision_enumerator,\n",
    "    print_number_of_trainable_model_parameters,\n",
    "    get_task_type,\n",
    ")\n",
    "from nyx.constants import (\n",
    "    COMPARISON_DATA_PATH,\n",
    "    SFT_DATA_OUTPUT_PATH,\n",
    "    COMMON_OUTPUT_PATHS,\n",
    "    SFT_PEFT_MERGED_MODEL_PATH,\n",
    "    SFT_PEFT_ADAPTER_PATH,\n",
    "    RM_TRAIN_DATA_PATH,\n",
    "    RM_OUTPUT_DIR,\n",
    "    RM_PEFT_ADAPTER_PATH,\n",
    "    RM_PEFT_MERGED_MODEL_PATH,\n",
    "    METRICS_PATH,\n",
    ")\n",
    "\n",
    "\n",
    "common_output_path = COMMON_OUTPUT_PATHS.format(RUN_ID=RUN_ID)\n",
    "\n",
    "SFT_PEFT_ADAPTER_PATH = SFT_PEFT_ADAPTER_PATH.format(\n",
    "    COMMON_OUTPUT_PATHS=common_output_path\n",
    ")\n",
    "SFT_PEFT_MERGED_MODEL_PATH = SFT_PEFT_MERGED_MODEL_PATH.format(\n",
    "    COMMON_OUTPUT_PATHS=common_output_path\n",
    ")\n",
    "\n",
    "RM_OUTPUT_DIR = RM_OUTPUT_DIR.format(COMMON_OUTPUT_PATHS=common_output_path)\n",
    "RM_PEFT_ADAPTER_PATH = RM_PEFT_ADAPTER_PATH.format(\n",
    "    COMMON_OUTPUT_PATHS=common_output_path\n",
    ")\n",
    "RM_PEFT_MERGED_MODEL_PATH = RM_PEFT_MERGED_MODEL_PATH.format(\n",
    "    COMMON_OUTPUT_PATHS=common_output_path\n",
    ")\n",
    "\n",
    "# if generated data from a different run needs to be utilised.\n",
    "if RM_TRAIN_DATA_RUN_ID is not None:\n",
    "    rm_common_path = COMMON_OUTPUT_PATHS.format(RUN_ID=RM_TRAIN_DATA_RUN_ID)\n",
    "    RM_TRAIN_DATA_PATH = RM_TRAIN_DATA_PATH.format(COMMON_OUTPUT_PATHS=rm_common_path)\n",
    "else:  # utilise current run_id\n",
    "    RM_TRAIN_DATA_PATH = RM_TRAIN_DATA_PATH.format(\n",
    "        COMMON_OUTPUT_PATHS=common_output_path\n",
    "    )\n",
    "\n",
    "METRICS_PATH = METRICS_PATH.format(COMMON_OUTPUT_PATHS=common_output_path)\n",
    "\n",
    "PRECISION = precision_enumerator(PRECISION_NAME)\n",
    "PRECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc63b85-1e21-42d8-873f-7eab599bb773",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55837b16-932f-4a7e-b2c0-4996fc17c991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2'],\n",
       "        num_rows: 18\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original dataset with train, test and validation\n",
    "comparison_dataset = load_from_disk(COMPARISON_DATA_PATH)\n",
    "\n",
    "# Train dataset with generated AI labels\n",
    "comparison_train_dataset = load_from_disk(RM_TRAIN_DATA_PATH)\n",
    "\n",
    "if TESTING is True:\n",
    "    comparison_dataset = comparison_dataset.filter(\n",
    "        lambda example, index: index % 4680 == 0, with_indices=True\n",
    "    )\n",
    "comparison_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26897fad-3569-4c97-b272-7974f4cdf771",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 512)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    sft_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        SFT_PEFT_MERGED_MODEL_PATH,\n",
    "        torch_dtype=PRECISION,\n",
    "        device_map=\"auto\",\n",
    "        # attn_implementation=\"flash_attention_2\",\n",
    "    )\n",
    "except ValueError:\n",
    "    sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        SFT_PEFT_MERGED_MODEL_PATH,\n",
    "        torch_dtype=PRECISION,\n",
    "        device_map=\"auto\",\n",
    "#         attn_implementation=\"flash_attention_2\",\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHOSEN_MODEL, padding_side='left')\n",
    "tokenizer.pad_token = (\n",
    "    tokenizer.pad_token if tokenizer.pad_token is not None else tokenizer.eos_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6405eb-8647-4a90-8213-7ffdd6d8f87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_summary_cols(example):\n",
    "    start_prompt = \"Summarize the following reddit post.\\n\\n\"\n",
    "    end_prompt = \"\\n\\nSummary: \"\n",
    "    example['summary_prompts_1'] = (\n",
    "        start_prompt + example[\"post\"] + end_prompt + example[\"candidate_summary_1\"]\n",
    "    )\n",
    "    example['summary_prompts_2'] = (\n",
    "        start_prompt + example[\"post\"] + end_prompt + example[\"candidate_summary_2\"]\n",
    "    )\n",
    "    return example\n",
    "\n",
    "\n",
    "comparison_train_dataset = comparison_train_dataset.map(create_summary_cols)\n",
    "\n",
    "# tokenized_train_dataset['train']['summary_prompts_1'][0]\n",
    "\n",
    "\n",
    "def prepare_for_reward_modelling(example, hf_baseline: bool = False):\n",
    "    choice_column = example[\"choice\"] if hf_baseline is True else example[\"ai_choice\"]\n",
    "    # ai_choice is based on index choice 0 ==summary 1, choice 1 == summary 2\n",
    "    example[\"accepted_summary\"] = (\n",
    "        example['summary_prompts_2']\n",
    "        if choice_column == example[\"constant_col\"]\n",
    "        else example['summary_prompts_1']\n",
    "    )\n",
    "    example[\"rejected_summary\"] = (\n",
    "        example['summary_prompts_1']\n",
    "        if choice_column == example[\"constant_col\"]\n",
    "        else example['summary_prompts_2']\n",
    "    )\n",
    "    return example\n",
    "\n",
    "\n",
    "comparison_train_dataset = comparison_train_dataset.map(prepare_for_reward_modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4680a11f-6ba4-4f7b-9088-b2dee2611d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2', 'prompts', 'ai_choice', 'constant_col', 'summary_prompts_1', 'summary_prompts_2', 'accepted_summary', 'rejected_summary'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38cb41-b8c7-4c34-a29e-db3019f7b728",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Encoder-Decoder specific line 29<br>\n",
    "Sampling from a range of start and end prompts could help robustness in the RM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a942bd41-67dc-4598-8ebe-69f1988cdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = (\n",
    "    tokenizer.pad_token if tokenizer.pad_token is not None else tokenizer.eos_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10614346-71ce-4aee-be5b-4a7cf693c573",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86e3ea38629432baa124a1f076ec640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected', 'labels'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    # start_prompt = \"Summarize the following reddit post.\\n\\n\"\n",
    "    # end_prompt = \"\\n\\nSummary: \"\n",
    "    # prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"post\"]]\n",
    "    accepted = tokenizer(\n",
    "        example[\"accepted_summary\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(DEVICE))\n",
    "    example[\"input_ids_chosen\"] = accepted.input_ids\n",
    "    example[\"attention_mask_chosen\"] = accepted.attention_mask\n",
    "    rejected = tokenizer(\n",
    "        example[\"rejected_summary\"],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(torch.device(DEVICE))\n",
    "    example[\"input_ids_rejected\"] = rejected.input_ids\n",
    "    example[\"attention_mask_rejected\"] = rejected.attention_mask\n",
    "\n",
    "    example[\"labels\"] = tokenizer(\n",
    "        [str(choice) for choice in example[\"ai_choice\"]],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).input_ids.to(torch.device(DEVICE))\n",
    "\n",
    "    if 'causal' in sft_model.config.architectures[0].lower():\n",
    "        example[\"decoder_input_ids\"] = sft_model._shift_right(example[\"labels\"])\n",
    "    return example\n",
    "\n",
    "\n",
    "reward_modelling_train_dataset = comparison_train_dataset.map(\n",
    "    tokenize_function, batched=True\n",
    ")\n",
    "reward_modelling_train_dataset = reward_modelling_train_dataset.remove_columns(\n",
    "    [\n",
    "        'subreddit',\n",
    "        'post',\n",
    "        'choice',\n",
    "        'candidate_summary_1',\n",
    "        'candidate_summary_2',\n",
    "        'prompts',\n",
    "        'ai_choice',\n",
    "        'constant_col',\n",
    "        'accepted_summary',\n",
    "        'rejected_summary',\n",
    "        'summary_prompts_2',\n",
    "        'summary_prompts_1',\n",
    "    ]  # 'is_match',\n",
    ")\n",
    "reward_modelling_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a0abd-4616-4465-942b-677aad7487b5",
   "metadata": {},
   "source": [
    "The below model is the pretrained SFT model with an additional head for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afbbbf3b-53e2-41d5-88c5-736aa3dff749",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MT5ForSequenceClassification were not initialized from the model checkpoint at ./experiments/316a2787976e4e848ea635422e2ef684/models/supervised-fine-tuning/merged-with-peft-adapter and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 712736\n",
      "all model parameters: 173095842\n",
      "percentage of trainable model parameters: 0.41%\n"
     ]
    }
   ],
   "source": [
    "base_reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    SFT_PEFT_MERGED_MODEL_PATH, torch_dtype=PRECISION\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    # Determines the size of LoRA matrices. x*r * r*y = x*y\n",
    "    r=RM_LORA_PARAM_R,\n",
    "    # scaling coefficient. Paper mentions it is important because the adjustments are small compared\n",
    "    # to the rest of the model.\n",
    "    lora_alpha=RM_LORA_PARAM_ALPHA,\n",
    "    # Variable target_modules determines what layers are fine-tuned, see architecture above.\n",
    "    # Simplest case scenario based on the original paper.\n",
    "    # The parameters / layers of the new head need to be enabled for training.\n",
    "    target_modules=RM_LORA_PARAM_TARGET_MODULES,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "rm_peft_model = get_peft_model(base_reward_model, lora_config)\n",
    "print(print_number_of_trainable_model_parameters(rm_peft_model))\n",
    "# base_reward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea0b1db0-0070-46c2-a48a-0f5c6b0ec118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected', 'labels'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_modelling_train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46e025ce-3743-4588-8b0d-0794610a9dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "training_args = RewardConfig(\n",
    "    output_dir=RM_OUTPUT_DIR,\n",
    "    # auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=RM_TRAIN_BATCH_SIZE,\n",
    "    save_steps=10_000,\n",
    "    learning_rate=RM_LEARNING_RATE,  # Higher learning rate than full fine-tuning.\n",
    "    logging_steps=1,\n",
    "    max_steps=len(reward_modelling_train_dataset['train']) // RM_TRAIN_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "reward_trainer = RewardTrainer(  # trainer class child\n",
    "    model=rm_peft_model,\n",
    "    args=training_args,  # trainerarguments child\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=reward_modelling_train_dataset['train'],\n",
    "    # num_labels=1, # Regression\n",
    ")\n",
    "\n",
    "# for _, param in peft_model.named_parameters():\n",
    "#         # all_model_params += param.numel()\n",
    "#         param.requires_grad = True\n",
    "# print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2675f352-0772-4c39-921c-d18f123853dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for dimension 1 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 3\u001B[0m reward_trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      4\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      6\u001B[0m duration \u001B[38;5;241m=\u001B[39m end \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/trainer.py:1859\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1857\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1858\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[1;32m   1860\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[1;32m   1861\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[1;32m   1862\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[1;32m   1863\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[1;32m   1864\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/trainer.py:2203\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2202\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2203\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs)\n\u001B[1;32m   2205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2206\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2207\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2208\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2209\u001B[0m ):\n\u001B[1;32m   2210\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2211\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/trainer.py:3138\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3137\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3138\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(model, inputs)\n\u001B[1;32m   3140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3141\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/trl/trainer/reward_trainer.py:228\u001B[0m, in \u001B[0;36mRewardTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_reward_data_collator:\n\u001B[1;32m    223\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    224\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe current compute_loss is implemented for RewardDataCollatorWithPadding,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m if you are using a custom data collator make sure you know what you are doing or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    226\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m implement your own compute_loss method.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    227\u001B[0m     )\n\u001B[0;32m--> 228\u001B[0m rewards_chosen \u001B[38;5;241m=\u001B[39m model(\n\u001B[1;32m    229\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids_chosen\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    230\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask_chosen\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    231\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    232\u001B[0m )[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    233\u001B[0m rewards_rejected \u001B[38;5;241m=\u001B[39m model(\n\u001B[1;32m    234\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids_rejected\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    235\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask_rejected\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    236\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    237\u001B[0m )[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# calculate loss, optionally modulate with margin\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/peft/peft_model.py:937\u001B[0m, in \u001B[0;36mPeftModelForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001B[0m\n\u001B[1;32m    935\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m peft_config\u001B[38;5;241m.\u001B[39mpeft_type \u001B[38;5;241m==\u001B[39m PeftType\u001B[38;5;241m.\u001B[39mPOLY:\n\u001B[1;32m    936\u001B[0m             kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m task_ids\n\u001B[0;32m--> 937\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model(\n\u001B[1;32m    938\u001B[0m             input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    939\u001B[0m             attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    940\u001B[0m             inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m    941\u001B[0m             labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m    942\u001B[0m             output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    943\u001B[0m             output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    944\u001B[0m             return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    945\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    946\u001B[0m         )\n\u001B[1;32m    948\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m _get_batch_size(input_ids, inputs_embeds)\n\u001B[1;32m    949\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    950\u001B[0m     \u001B[38;5;66;03m# concat prompt attention mask\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:161\u001B[0m, in \u001B[0;36mBaseTuner.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any):\n\u001B[0;32m--> 161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/models/mt5/modeling_mt5.py:2127\u001B[0m, in \u001B[0;36mMT5ForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   2125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll examples must have the same number of <eos> tokens.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2126\u001B[0m batch_size, _, hidden_size \u001B[38;5;241m=\u001B[39m sequence_output\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m-> 2127\u001B[0m sentence_representation \u001B[38;5;241m=\u001B[39m sequence_output[eos_mask, :]\u001B[38;5;241m.\u001B[39mview(batch_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, hidden_size)[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n\u001B[1;32m   2128\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassification_head(sentence_representation)\n\u001B[1;32m   2130\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: index -1 is out of bounds for dimension 1 with size 0"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "reward_trainer.train()\n",
    "end = time.time()\n",
    "\n",
    "duration = end - start\n",
    "print(end)\n",
    "print(f\"Training for 1 epoch took {round(duration, 2)} seconds to execute.\")\n",
    "\n",
    "reward_trainer.model.save_pretrained(RM_PEFT_ADAPTER_PATH)\n",
    "tokenizer.save_pretrained(RM_PEFT_ADAPTER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0958ff-a546-4a45-b658-c5a047c079d5",
   "metadata": {},
   "source": [
    "### Reload and evaluate RM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e2b55-4b46-4dc6-9336-9f9c07592a08",
   "metadata": {},
   "source": [
    "### Merge and save RM model (with base model)\n",
    "So that, the sentiment pipe warning is eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da40dc71-09f9-485c-9aad-a289960ba6d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging and saving the model which is trained all the way (i.e., utilising all of the data).\n",
    "merged_rm_model = rm_peft_model.merge_and_unload()\n",
    "merged_rm_model.save_pretrained(RM_PEFT_MERGED_MODEL_PATH)\n",
    "\n",
    "merged_rm_model.to(torch.device(DEVICE))\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9db1ed0-72cc-40f4-8739-0de204a2c166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Loop this over [base, 500, 1000, 5000, 10_000, 50_000, 100_000] to calculate the pairwise accuracy\n",
    "\n",
    "\n",
    "# peft_rm_model = PeftModel.from_pretrained(base_reward_model,\n",
    "#                                        f'{rm_peft_model_path}',\n",
    "#                                        torch_dtype=PRECISION,\n",
    "#                                        is_trainable=False)\n",
    "\n",
    "# peft_rm_model.to(torch.device('mps'))\n",
    "# print('PEFT trained RM is loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e71a9-55a7-473c-8bd4-2470cbfc68b2",
   "metadata": {},
   "source": [
    "### _Comparing HF and AIF data (RM model generated)_\n",
    "Utilising the train test split function to select a random 15% of the validation set to compare HF and AIF labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25280a3c-3f3d-4386-853f-ef811f5f022a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "rm_eval_data = comparison_dataset['validation'].train_test_split(\n",
    "    test_size=0.15, seed=RANDOM_SEED\n",
    ")\n",
    "rm_eval_data['test']\n",
    "print(len(rm_eval_data['test']))\n",
    "\n",
    "\n",
    "def get_rm_probabilities(\n",
    "    col: str, rm_model_to_evaluate=merged_rm_model\n",
    ") -> List[List[str]]:\n",
    "    candidate = rm_model_to_evaluate(\n",
    "        tokenizer(\n",
    "            rm_eval_data['test'][col],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids.to(DEVICE)\n",
    "    )\n",
    "\n",
    "    candidate_probabilities = candidate.logits.softmax(dim=-1).tolist()\n",
    "    return candidate_probabilities\n",
    "\n",
    "\n",
    "candidate_1_probabilities = get_rm_probabilities('candidate_summary_1')\n",
    "candidate_2_probabilities = get_rm_probabilities('candidate_summary_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc60384-48ea-4608-a4c6-c412fe1c8a59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a69d73a1c4471d9aea038008cba27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Reward Model (RM) is in agreement with the annotator provided labels: 0.0% of the times.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['subreddit', 'post', 'choice', 'candidate_summary_1', 'candidate_summary_2', 'candidate_1_preference_probability', 'candidate_2_preference_probability', 'rm_choice', 'is_match'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the first item in probabilities will yield the probability of being a chosen summary.\n",
    "rm_eval_data['test'] = rm_eval_data['test'].add_column(\n",
    "    name=\"candidate_1_preference_probability\",\n",
    "    column=[item[0] for item in candidate_1_probabilities],\n",
    ")\n",
    "rm_eval_data['test'] = rm_eval_data['test'].add_column(\n",
    "    name=\"candidate_2_preference_probability\",\n",
    "    column=[item[0] for item in candidate_2_probabilities],\n",
    ")\n",
    "\n",
    "\n",
    "def get_rm_labels(example):\n",
    "    example[\"rm_choice\"] = (\n",
    "        0\n",
    "        if example[\"candidate_1_preference_probability\"]\n",
    "        >= example[\"candidate_2_preference_probability\"]\n",
    "        else 1\n",
    "    )\n",
    "    example[\"is_match\"] = 1 if example[\"choice\"] == example[\"rm_choice\"] else 0\n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply the function to each example in the dataset\n",
    "rm_eval_data['test'] = rm_eval_data['test'].map(get_rm_labels)\n",
    "\n",
    "# Calculate the mean value of the 'is_match' feature\n",
    "rm_aggreement_mean_value = np.round(np.mean(rm_eval_data['test'][\"is_match\"]) * 100, 2)\n",
    "print(\n",
    "    f\"The Reward Model (RM) is in agreement with the annotator provided labels: {rm_aggreement_mean_value}% of the times.\"\n",
    ")\n",
    "rm_eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "768397aa-c869-405c-8459-7a2ebc7cdda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c422653ed54609bcda2749d306649a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt driven, instruct model generated feedback labels are in agreement with the annotator provided labels: 0.0% of the times.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           1       0.00      0.00      0.00       3.0\n",
      "\n",
      "    accuracy                           0.00       3.0\n",
      "   macro avg       0.00      0.00      0.00       3.0\n",
      "weighted avg       0.00      0.00      0.00       3.0\n",
      "\n",
      "tp: 0, fp: 0\n",
      "fn: 3, tn: 0\n",
      "MCC is 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluator = AILabelEvaluator(data_to_evaluate=rm_eval_data, run_id=RUN_ID)\n",
    "\n",
    "evaluator.compute_metrics(data_split='test', predicted_col='rm_choice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9c288-ad4f-49af-9915-417a9e1ef57f",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc4231f3-4225-421f-8f08-8985d2ec6b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 116722\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 6553\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 6447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(SFT_DATA_OUTPUT_PATH)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1719748-0188-4a0a-badb-71f0ca54df36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 25\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TESTING is True:\n",
    "    dataset = dataset.filter(\n",
    "        lambda example, index: index % 4680 == 0, with_indices=True\n",
    "    )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0249e3a2-1574-4afd-ae97-a61c042964a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 688128\n",
      "all model parameters: 300864896\n",
      "percentage of trainable model parameters: 0.23%\n"
     ]
    }
   ],
   "source": [
    "rl_lora_config = LoraConfig(\n",
    "    r=RL_LORA_PARAM_R,  # Rank\n",
    "    lora_alpha=RL_LORA_PARAM_ALPHA,\n",
    "    target_modules=RL_LORA_PARAM_TARGET_MODULES,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=get_task_type(model=sft_model),\n",
    ")\n",
    "\n",
    "\n",
    "rl_peft_model = get_peft_model(sft_model, rl_lora_config)\n",
    "print(print_number_of_trainable_model_parameters(rl_peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8571a9c-4df0-45d8-8200-44976b8625b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model has trainable model parameters: 688641\n",
      "all model parameters: 300865409\n",
      "percentage of trainable model parameters: 0.23%\n",
      "\n",
      "AutoModelForSeq2SeqLMWithValueHead(\n",
      "  (pretrained_model): PeftModelForSeq2SeqLM(\n",
      "    (base_model): LoraModel(\n",
      "      (model): MT5ForConditionalGeneration(\n",
      "        (shared): Embedding(250112, 512)\n",
      "        (encoder): MT5Stack(\n",
      "          (embed_tokens): Embedding(250112, 512)\n",
      "          (block): ModuleList(\n",
      "            (0): MT5Block(\n",
      "              (layer): ModuleList(\n",
      "                (0): MT5LayerSelfAttention(\n",
      "                  (SelfAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                    (relative_attention_bias): Embedding(32, 6)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (1): MT5LayerFF(\n",
      "                  (DenseReluDense): MT5DenseGatedActDense(\n",
      "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                    (act): NewGELUActivation()\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1-7): 7 x MT5Block(\n",
      "              (layer): ModuleList(\n",
      "                (0): MT5LayerSelfAttention(\n",
      "                  (SelfAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (1): MT5LayerFF(\n",
      "                  (DenseReluDense): MT5DenseGatedActDense(\n",
      "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                    (act): NewGELUActivation()\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (decoder): MT5Stack(\n",
      "          (embed_tokens): Embedding(250112, 512)\n",
      "          (block): ModuleList(\n",
      "            (0): MT5Block(\n",
      "              (layer): ModuleList(\n",
      "                (0): MT5LayerSelfAttention(\n",
      "                  (SelfAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                    (relative_attention_bias): Embedding(32, 6)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (1): MT5LayerCrossAttention(\n",
      "                  (EncDecAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (2): MT5LayerFF(\n",
      "                  (DenseReluDense): MT5DenseGatedActDense(\n",
      "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                    (act): NewGELUActivation()\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1-7): 7 x MT5Block(\n",
      "              (layer): ModuleList(\n",
      "                (0): MT5LayerSelfAttention(\n",
      "                  (SelfAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (1): MT5LayerCrossAttention(\n",
      "                  (EncDecAttention): MT5Attention(\n",
      "                    (q): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (v): lora.Linear(\n",
      "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                      (lora_dropout): ModuleDict(\n",
      "                        (default): Dropout(p=0.05, inplace=False)\n",
      "                      )\n",
      "                      (lora_A): ModuleDict(\n",
      "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
      "                      )\n",
      "                      (lora_B): ModuleDict(\n",
      "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
      "                      )\n",
      "                      (lora_embedding_A): ParameterDict()\n",
      "                      (lora_embedding_B): ParameterDict()\n",
      "                    )\n",
      "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (2): MT5LayerFF(\n",
      "                  (DenseReluDense): MT5DenseGatedActDense(\n",
      "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                    (act): NewGELUActivation()\n",
      "                  )\n",
      "                  (layer_norm): MT5LayerNorm()\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layer_norm): MT5LayerNorm()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (v_head): ValueHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (summary): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoModelForSeq2SeqLMWithValueHead(\n",
       "  (pretrained_model): PeftModelForSeq2SeqLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): MT5ForConditionalGeneration(\n",
       "        (shared): Embedding(250112, 512)\n",
       "        (encoder): MT5Stack(\n",
       "          (embed_tokens): Embedding(250112, 512)\n",
       "          (block): ModuleList(\n",
       "            (0): MT5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): MT5LayerSelfAttention(\n",
       "                  (SelfAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                    (relative_attention_bias): Embedding(32, 6)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): MT5LayerFF(\n",
       "                  (DenseReluDense): MT5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1-7): 7 x MT5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): MT5LayerSelfAttention(\n",
       "                  (SelfAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): MT5LayerFF(\n",
       "                  (DenseReluDense): MT5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (final_layer_norm): MT5LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (decoder): MT5Stack(\n",
       "          (embed_tokens): Embedding(250112, 512)\n",
       "          (block): ModuleList(\n",
       "            (0): MT5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): MT5LayerSelfAttention(\n",
       "                  (SelfAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                    (relative_attention_bias): Embedding(32, 6)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): MT5LayerCrossAttention(\n",
       "                  (EncDecAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (2): MT5LayerFF(\n",
       "                  (DenseReluDense): MT5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1-7): 7 x MT5Block(\n",
       "              (layer): ModuleList(\n",
       "                (0): MT5LayerSelfAttention(\n",
       "                  (SelfAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (1): MT5LayerCrossAttention(\n",
       "                  (EncDecAttention): MT5Attention(\n",
       "                    (q): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (v): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.05, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (2): MT5LayerFF(\n",
       "                  (DenseReluDense): MT5DenseGatedActDense(\n",
       "                    (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    (act): NewGELUActivation()\n",
       "                  )\n",
       "                  (layer_norm): MT5LayerNorm()\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (final_layer_norm): MT5LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(\n",
    "    rl_peft_model, torch_dtype=PRECISION, is_trainable=True\n",
    ")\n",
    "\n",
    "print(f'PPO model has {print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model)\n",
    "ppo_model.to(torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f926a-88c4-47db-a9dd-5c742731ba31",
   "metadata": {},
   "source": [
    "The below function could also be adapted to sample from a variety of prompts to improve exploration and improve\n",
    "robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "159cfba9-435f-4afd-88a2-00a114fa956b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bdcdedca3b412c817a7a2b3db72a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\n",
       "        num_rows: 25\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'subreddit', 'title', 'post', 'summary', 'input_ids', 'query'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_for_rl(sample):\n",
    "    # Wrap each dialogue with the instruction.\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following reddit post.\n",
    "\n",
    "{sample[\"post\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "    sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "\n",
    "    # Requirement for PPO library.\n",
    "    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "    return sample\n",
    "\n",
    "\n",
    "# Tokenize each dialogue.\n",
    "dataset = dataset.map(tokenize_for_rl, batched=False)\n",
    "dataset.set_format(type=\"torch\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddc80b03-568d-4ea4-990c-8264e8142fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "trainable model parameters: 0\n",
      "all model parameters: 300865409\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "ref_model.to(torch.device(DEVICE))\n",
    "print(\n",
    "    f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8a7ee22-9c33-40d1-af58-996b9e236ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}, {'key1': 'value2', 'key2': 'value3', 'key3': 'value4'}]\n",
      "Collator output: {'key1': ['value1', 'value2'], 'key2': ['value2', 'value3'], 'key3': ['value3', 'value4']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    {\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"},\n",
    "    {\"key1\": \"value2\", \"key2\": \"value3\", \"key3\": \"value4\"},\n",
    "]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6826a3d-2c88-4011-af76-6ec5be7bea6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = PPOConfig(\n",
    "    # Name of model to use - used only for tracking purposes\n",
    "    model_name=CHOSEN_MODEL,\n",
    "    learning_rate=RL_LEARNING_RATE,\n",
    "    ppo_epochs=RL_N_EPOCHS,\n",
    "    mini_batch_size=RL_TRAIN_MINI_BATCH_SIZE,\n",
    "    batch_size=RL_TRAIN_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config=config,\n",
    "    model=ppo_model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset[\"train\"],\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70529ba8-fe82-40bb-82e6-c0bf19c42369",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\", model=merged_rm_model, tokenizer=tokenizer, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "039d4017-d2a2-453f-9e83-b4fd7640a55e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m     max_new_tokens \u001B[38;5;241m=\u001B[39m output_length_sampler()        \n\u001B[1;32m     38\u001B[0m     generation_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_new_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m max_new_tokens\n\u001B[0;32m---> 39\u001B[0m     summary \u001B[38;5;241m=\u001B[39m ppo_trainer\u001B[38;5;241m.\u001B[39mgenerate(prompt_tensor, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgeneration_kwargs)\n\u001B[1;32m     41\u001B[0m     summary_tensors\u001B[38;5;241m.\u001B[39mappend(summary\u001B[38;5;241m.\u001B[39msqueeze()[\u001B[38;5;241m-\u001B[39mmax_new_tokens:])\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# This needs to be called \"response\".\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/trl/trainer/ppo_trainer.py:497\u001B[0m, in \u001B[0;36mPPOTrainer.generate\u001B[0;34m(self, query_tensor, length_sampler, batch_size, return_prompt, generate_ref_response, **generation_kwargs)\u001B[0m\n\u001B[1;32m    494\u001B[0m     generation_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_new_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m length_sampler()\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m unwrap_model_for_generation(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator) \u001B[38;5;28;01mas\u001B[39;00m unwrapped_model:\n\u001B[0;32m--> 497\u001B[0m     response \u001B[38;5;241m=\u001B[39m unwrapped_model\u001B[38;5;241m.\u001B[39mgenerate(input_ids\u001B[38;5;241m=\u001B[39mquery_tensor\u001B[38;5;241m.\u001B[39munsqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgeneration_kwargs)\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generate_ref_response:\n\u001B[1;32m    500\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m unwrap_model_for_generation(\n\u001B[1;32m    501\u001B[0m         ref_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator, is_peft_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_peft_model\n\u001B[1;32m    502\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m unwrapped_model:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/trl/models/modeling_value_head.py:438\u001B[0m, in \u001B[0;36mAutoModelForSeq2SeqLMWithValueHead.generate\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    435\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;124;03m    We call `generate` on the wrapped model.\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpretrained_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/peft/peft_model.py:1441\u001B[0m, in \u001B[0;36mPeftModelForSeq2SeqLM.generate\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m   1439\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_peft_forward_hooks(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1440\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspecial_peft_forward_args}\n\u001B[0;32m-> 1441\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1442\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/generation/utils.py:1622\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1614\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1615\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1616\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   1617\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1618\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1619\u001B[0m     )\n\u001B[1;32m   1621\u001B[0m     \u001B[38;5;66;03m# 13. run sample\u001B[39;00m\n\u001B[0;32m-> 1622\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample(\n\u001B[1;32m   1623\u001B[0m         input_ids,\n\u001B[1;32m   1624\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[1;32m   1625\u001B[0m         logits_warper\u001B[38;5;241m=\u001B[39mlogits_warper,\n\u001B[1;32m   1626\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[1;32m   1627\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[1;32m   1628\u001B[0m         output_scores\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_scores,\n\u001B[1;32m   1629\u001B[0m         output_logits\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_logits,\n\u001B[1;32m   1630\u001B[0m         return_dict_in_generate\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mreturn_dict_in_generate,\n\u001B[1;32m   1631\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[1;32m   1632\u001B[0m         streamer\u001B[38;5;241m=\u001B[39mstreamer,\n\u001B[1;32m   1633\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1634\u001B[0m     )\n\u001B[1;32m   1636\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH:\n\u001B[1;32m   1637\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   1638\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   1639\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1640\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1645\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   1646\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/generation/utils.py:2804\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2801\u001B[0m next_token_logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n\u001B[1;32m   2803\u001B[0m \u001B[38;5;66;03m# pre-process distribution\u001B[39;00m\n\u001B[0;32m-> 2804\u001B[0m next_token_scores \u001B[38;5;241m=\u001B[39m logits_processor(input_ids, next_token_logits)\n\u001B[1;32m   2805\u001B[0m next_token_scores \u001B[38;5;241m=\u001B[39m logits_warper(input_ids, next_token_scores)\n\u001B[1;32m   2807\u001B[0m \u001B[38;5;66;03m# Store scores, attentions and hidden_states when required\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/generation/logits_process.py:98\u001B[0m, in \u001B[0;36mLogitsProcessorList.__call__\u001B[0;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 98\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores)\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/transformers/generation/logits_process.py:156\u001B[0m, in \u001B[0;36mMinLengthLogitsProcessor.__call__\u001B[0;34m(self, input_ids, scores)\u001B[0m\n\u001B[1;32m    154\u001B[0m vocab_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], device\u001B[38;5;241m=\u001B[39mscores\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    155\u001B[0m eos_token_id \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meos_token_id, device\u001B[38;5;241m=\u001B[39mscores\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 156\u001B[0m eos_token_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39misin(vocab_tensor, eos_token_id)\n\u001B[1;32m    157\u001B[0m scores_processed \u001B[38;5;241m=\u001B[39m scores\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_length:\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 3_500\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "preferred_summary_index = 0\n",
    "\n",
    "generation_kwargs = {\"min_length\": 5, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None,  # Return all scores.\n",
    "    \"function_to_apply\": \"none\",  # Raw logits without softmax.\n",
    "    \"batch_size\": RL_TRAIN_BATCH_SIZE,\n",
    "}\n",
    "\n",
    "max_ppo_steps = 5\n",
    "\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # print(step, batch)\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [\n",
    "        torch.tensor(reward[preferred_summary_index][\"score\"]) for reward in rewards\n",
    "    ]\n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936573c-40c9-4aa4-aa3a-4ecdc9970131",
   "metadata": {},
   "source": [
    "### _Evaluate RL model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232e2e6-7acf-4745-8fa7-27370ecd98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EVAL_SAMPLES = int(len(tokenized_datasets['test']) * 0.15)\n",
    "\n",
    "start = time.time()\n",
    "peft_checkpoint_generation = quantitative_comparison(\n",
    "    ppo_model,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    n_samples_to_evaluate=N_EVAL_SAMPLES,\n",
    "    batch_size=2,\n",
    "    device=DEVICE,\n",
    ")\n",
    "baseline_model_generation = quantitative_comparison(\n",
    "    sft_model,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    n_samples_to_evaluate=N_EVAL_SAMPLES,\n",
    "    batch_size=2,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "duration = end - start\n",
    "print(\n",
    "    f\"Evaluating N={N_EVAL_SAMPLES} samples took {round(duration, 2)} seconds to execute.\"\n",
    ")\n",
    "\n",
    "human_baseline_answer = dataset[\"test\"][0:N_EVAL_SAMPLES][\"summary\"]\n",
    "\n",
    "zipped_summaries = list(\n",
    "    zip(human_baseline_answer, peft_checkpoint_generation, baseline_model_generation)\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    zipped_summaries,\n",
    "    columns=[\n",
    "        \"human_baseline_answer\",\n",
    "        \"peft_checkpoint_generation\",\n",
    "        \"baseline_model_generation\",\n",
    "    ],\n",
    ")\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74442b-4c6f-416d-926e-1065d3d09055",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=baseline_model_generation,\n",
    "    references=human_baseline_answer[0 : len(baseline_model_generation)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_checkpoint_generation,\n",
    "    references=human_baseline_answer[0 : len(peft_checkpoint_generation)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "original_model_results = round_dictionary_values(original_model_results)\n",
    "# instruct_model_results = round_dictionary_values(instruct_model_results)\n",
    "peft_model_results = round_dictionary_values(peft_model_results)\n",
    "print(\"SFT MODEL:\")\n",
    "print(original_model_results)\n",
    "# print('INSTRUCT MODEL:')\n",
    "# print(instruct_model_results)\n",
    "print(\"PEFT MODEL:\")\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec52cc9-3ce9-40b9-9d40-e46d458880d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(METRICS_PATH):\n",
    "    os.makedirs(METRICS_PATH)\n",
    "\n",
    "data_path = f'{METRICS_PATH}/rl-results.json'\n",
    "\n",
    "results_dict = {'sft-model': original_model_results, 'rl-model': peft_model_results}\n",
    "with open(data_path, 'w') as file:\n",
    "    json.dump(results_dict, file)\n",
    "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
    "\n",
    "improvement = np.array(list(peft_model_results.values())) - np.array(\n",
    "    list(original_model_results.values())\n",
    ")\n",
    "for key, value in zip(peft_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22f46a-2420-4993-8bd8-8d2be78c86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more eval, for higher rated summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca6f26e-9f26-40d6-81d8-a607004b6c5a",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-diss",
   "language": "python",
   "name": "llm-diss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
