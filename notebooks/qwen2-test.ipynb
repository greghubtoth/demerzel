{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233e8da6-b2f2-4ab8-b7a8-157885c7849a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = \"mps\"  # the device to load the model onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4b5fb7-5a88-4e2a-9fca-06a5f8716c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b625fda7c1c43d1b2b740926f611bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3133d73ae21f459c8d0cf919345b0a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a67d8595d7944618f35e59eb59d7ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed739cbf824f80a34be62ecfee210c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1952d3d07eae4c3d966e9f96e25e7d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766c52dfdca40c8b1b64dca06717124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec64a550eba403c8746d8eee83a3bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    torch_dtype=torch.half,\n",
    "    # device_map=\"auto\"\n",
    ")\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a4a7045-a2ee-4248-a30c-b16c02ca3159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"Tell me succinctly what qwen means.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faef84b3-744f-4a79-97a1-ee859d9db548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen is a large language model created by Alibaba Cloud, which was released in 2021. It is the first AI language model developed on a commercially available platform and can understand and generate text across multiple languages. Qwen's capabilities include natural language understanding, generation, and translation.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e57ddaa-2bab-4bed-b254-cc1bad96aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A large language model is a type of artificial intelligence that can generate text using natural language in multiple languages, and it uses the principles of machine learning to learn from vast amounts of data.\\n\\nThe process of generating text involves several steps:\\n\\n1. Data collection: The first step is collecting data about the language models. This could include text samples from different sources such as books, articles, or social media posts.\\n\\n2. Training: Once the data has been collected, the next step is to train the model on this data. This involves feeding the model with new text samples and training it on a set of labeled examples that represent the types of texts that the model will eventually produce.\\n\\n3. Evaluation: After training, the model needs to be evaluated on a set of test data to see how well it performs. This involves comparing the generated text against the actual text produced by the model.\\n\\n4. Improvement: As the model learns more, it may improve its ability to generate text that better reflects the nuances of human language.\\n\\nOverall, the goal of large language models is to provide humans with access to a vast amount of information in their native language, while also allowing them to create content that is both informative and engaging.<|im_end|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c4b7f3-e4c8-4ae5-a0a8-e2d3576e73a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Tell me succinctly what qwen means.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a28be5-6811-409d-ac5f-d2ae90afa1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcba43f3-8dc8-4d59-bb26-63b5002bc078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Summarise the following article:\n",
      "My boyfriend and I are long distance. We have a trip planned this summer which involves me going over to him in the USA. This will be the second time I have actually been with him in person. I am flying from the UK with my mum to the east coast. The original plan was for me to fly over to my boyfriend in the west coast (my parents are holidaying on the east coast) but because my mum was freaking out so much about me going to meet my boyfriend i said we can all road trip there together. I even invited her on the trip with us. I have given her all of our dates so that she can travel around with us.\n",
      "\n",
      "The plan was for me to stay on the 4th July and fly back on the 5th. Mum knew this. I told her I had booked a flight back already from the west coast to east coast (where she would pick me up and we would fly back to the UK together). She has gone mad at me because she can't believe I would book a flight when she told me she didn't want me flying on my own. At the time I had booked it she told me she wasn't gonna road trip with us. She knew the trip was happening.......how else was I to get home if I don't fly? \n",
      "\n",
      "I am fine flying on my own it doesn't bother me at all. I feel like I have done everything I can to make her feel comfortable with this trip and she is just trying to sabotage it. Thoughts??<|im_end|>\n",
      "<|im_start|>assistant\n",
      "This person's partner lives in the US, but they're both based in the UK. They were planning to meet their partner in the US during the Fourth of July weekend, but their mother refused to go along with them. The person who wrote this text wants to know what other options they have to return home safely and comfortably.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"<|im_start|>user\n",
    "Summarise the following article:\n",
    "My boyfriend and I are long distance. We have a trip planned this summer which involves me going over to him in the USA. This will be the second time I have actually been with him in person. I am flying from the UK with my mum to the east coast. The original plan was for me to fly over to my boyfriend in the west coast (my parents are holidaying on the east coast) but because my mum was freaking out so much about me going to meet my boyfriend i said we can all road trip there together. I even invited her on the trip with us. I have given her all of our dates so that she can travel around with us.\\n\\nThe plan was for me to stay on the 4th July and fly back on the 5th. Mum knew this. I told her I had booked a flight back already from the west coast to east coast (where she would pick me up and we would fly back to the UK together). She has gone mad at me because she can't believe I would book a flight when she told me she didn't want me flying on my own. At the time I had booked it she told me she wasn't gonna road trip with us. She knew the trip was happening.......how else was I to get home if I don't fly? \\n\\nI am fine flying on my own it doesn't bother me at all. I feel like I have done everything I can to make her feel comfortable with this trip and she is just trying to sabotage it. Thoughts??<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": prompt}\n",
    "# ]\n",
    "# text = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=False,\n",
    "#     add_generation_prompt=True\n",
    "# )\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "\n",
    "response_2 = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adde2f2d-336d-489c-953b-f39acfe2d1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>user\\nSummarise the following article:\\nMy boyfriend and I are long distance. We have a trip planned this summer which involves me going over to him in the USA. This will be the second time I have actually been with him in person. I am flying from the UK with my mum to the east coast. The original plan was for me to fly over to my boyfriend in the west coast (my parents are holidaying on the east coast) but because my mum was freaking out so much about me going to meet my boyfriend i said we can all road trip there together. I even invited her on the trip with us. I have given her all of our dates so that she can travel around with us.\\n\\nThe plan was for me to stay on the 4th July and fly back on the 5th. Mum knew this. I told her I had booked a flight back already from the west coast to east coast (where she would pick me up and we would fly back to the UK together). She has gone mad at me because she can't believe I would book a flight when she told me she didn't want me flying on my own. At the time I had booked it she told me she wasn't gonna road trip with us. She knew the trip was happening.......how else was I to get home if I don't fly? \\n\\nI am fine flying on my own it doesn't bother me at all. I feel like I have done everything I can to make her feel comfortable with this trip and she is just trying to sabotage it. Thoughts??<|im_end|>\\n<|im_start|>assistant\\nThis person's partner lives in the US, but they're both based in the UK. They were planning to meet their partner in the US during the Fourth of July weekend, but their mother refused to go along with them. The person who wrote this text wants to know what other options they have to return home safely and comfortably.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_text = 'asdf <|im_end|>'\n",
    "\n",
    "\n",
    "response_2[: -len('<|im_end|>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8638864-1ce9-4485-8d21-4e0c36adddbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
