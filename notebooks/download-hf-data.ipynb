{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cacba74-c344-441b-a505-1bb929257da9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install langchain_core langchain_community sentence_transformers weaviate_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9d256f-2b39-4a26-bb4d-2d9bd872d6a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Weaviate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a715dd8-2120-49ec-83f4-ee6bc3fc92e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import weaviate\n",
    "import ssl\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = ''  # disables cert validation\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    GenerationConfig,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "# dataset_name = \"openai/summarize_from_feedback\"\n",
    "# dataset = load_dataset(dataset_name, name='comparisons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99dcdb34-7a53-4974-b258-020b0aa08ca5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"  # \"sentence-transformers/paraphrase-MiniLM-L6-v2\"  #\n",
    "model_kwargs = {'device': 'mps'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    "    # force_download=True,\n",
    ")\n",
    "\n",
    "model_id = \"microsoft/phi-1_5\"  # \"microsoft/Phi-3-mini-4k-instruct\" #\"google/flan-t5-xl\" # \"/Users/gtoth/Documents/models/gemma-2b-it\" # #  # #\"microsoft/phi-1_5\" #\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)  # AutoModelForSeq2SeqLM\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    device=\"mps\",\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19121ad7-545e-432e-9dcd-3aebf759944f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/owner/.cache/weaviate-embedded: process ID 11346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-06-25T19:25:53+01:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-06-25T19:25:53+01:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-06-25T19:25:53+01:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-06-25T19:25:54+01:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-06-25T19:25:54+01:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-06-25T19:25:54+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=weaviate.embedded.EmbeddedOptions(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328700e9-db3d-484b-b064-e091f7d880c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/opt/anaconda3/envs/llm-diss/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_d0603ed15bfe46af86a1781748edbfb2_LqzV9Z2FkQ6I in 2.641044ms\",\"time\":\"2024-06-25T19:25:54+01:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-06-25T19:25:54+01:00\",\"took\":302758}\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\"Categories:\n",
    "0. Unknown category.\n",
    "1. Intents related to flights.\n",
    "2. Intents related to hotel booking.\n",
    "Intents:\n",
    "0.0 Unknown intent.\n",
    "1.0. The user wants to check the status of a flight.\n",
    "1.1. The user wants to book a flight.\n",
    "\n",
    "Utterance: I would like to make a flight booking.\n",
    "Intent: 1.1\"\"\",\n",
    "        metadata={\"example\": \"basic\"},\n",
    "    ),\n",
    "]\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    [],\n",
    "    embeddings,\n",
    "    weaviate_url=\"http://127.0.0.1:8079\",  # \"http://127.0.0.1:8079\"\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d776509-08db-48f9-ae44-8f5946f137c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(k=2)  # search_type=\"hybrid\", alpha=0.5, beta=0.99\n",
    "# docsearch.as_retriever(\n",
    "#                 search_type=\"similarity_score_threshold\",\n",
    "#                 search_kwargs={'score_threshold': 0.8}\n",
    "#             )\n",
    "# from langchain_community.retrievers import WeaviateHybridSearchRetriever\n",
    "\n",
    "# retriever = WeaviateHybridSearchRetriever(\n",
    "#     client=client,\n",
    "#     index_name=\"LangChain\",\n",
    "#     text_key=\"text\",\n",
    "#     attributes=[],\n",
    "#     # create_schema_if_missing=True,\n",
    "#     alpha=0.5,\n",
    "#     k=2\n",
    "# )\n",
    "#\n",
    "# def get_content_str_from_docs(retrieved_documents: List[Document]) -> str:\n",
    "#     relevant_content = (\n",
    "#         [doc.page_content for doc in retrieved_documents] if len(retrieved_documents) >= 1 else []\n",
    "#     )\n",
    "#     return '\\n'.join(relevant_content)\n",
    "# example_retriever = vectorstore.as_retriever(\n",
    "#                 search_kwargs={\n",
    "#                     \"k\": 1,\n",
    "#                     \"where_filter\": {\"path\": [\"type\"], \"operator\": \"Equal\", \"valueString\": \"example\"},\n",
    "#                 }\n",
    "#             )\n",
    "#\n",
    "# intent_retriever = vectorstore.as_retriever(\n",
    "#     search_type=search_kwargs[\"search_type\"],\n",
    "#     search_kwargs={\n",
    "#         \"k\": search_kwargs[\"k\"],\n",
    "#         \"where_filter\": {\"path\": [\"type\"], \"operator\": \"Equal\", \"valueString\": \"intent\"},\n",
    "#     },\n",
    "# )\n",
    "# # prompt_assembly_chain = {\"utterance\": itemgetter(\"utterance\"),\n",
    "# #                                  \"language_code\": itemgetter(\"language_code\"),\n",
    "# #                                  \"example\": itemgetter(\"utterance\")\n",
    "# #                                             | example_retriever\n",
    "# #                                             | RunnableLambda(get_content_str_from_docs),\n",
    "# #                                  # \"categories\": itemgetter(\"utterance\") | category_retriever,\n",
    "# #                                  \"intents\": itemgetter(\"utterance\")\n",
    "# #                                             | intent_retriever\n",
    "# #                                             | RunnableLambda(get_content_str_from_docs),\n",
    "# #                                             # itemgetter(\"intents_str\"),\n",
    "# #                                  } | prompt\n",
    "# #\n",
    "# # correct_example = [Document(\n",
    "# #                             page_content=f\"\"\"Intents:\n",
    "# # {retrieved_intents}\n",
    "# # Intent: {response['intent']}\"\"\",\n",
    "# #                             metadata={\"type\": \"example\", \"origin\": \"collected\"},\n",
    "# #                         )]\n",
    "# #                         # print(correct_example)\n",
    "# #                         example_retriever.add_documents(documents=correct_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4da437fb-15aa-4796-92a4-c3ac02f6a0f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"<bos>You're an intent classifier for language: '{language_code}'.\n",
    "Analyze the utterance and choose the most relevant intent and category from the list that best matches the utterance.\n",
    "    - Use only the provided intents and categories.\n",
    "    - Return \"0.0\" if no intents and category match.\n",
    "    - Return only the number of the most relevant intent and nothing else.\n",
    "    \n",
    "<example>\n",
    "{example}\n",
    "</example>\n",
    "    \n",
    "Categories:\n",
    "{categories}\n",
    "Intents:\n",
    "{intents}\n",
    "\n",
    "Utterance: {utterance}\n",
    "Intent:\"\"\"\n",
    "# Instantiation using from_template (recommended)\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# prompt.format(foo=\"bar\")\n",
    "\n",
    "# Instantiation using initializer\n",
    "# prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb648941-4d23-48a5-8b89-4fcef3f38dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "json_path = '/Users/gtoth/PycharmProjects/grok/grok_intent_evaluation/cortex_bank_bot_definition_1.json'\n",
    "\n",
    "with open(json_path) as f:\n",
    "    intents_config = json.load(f)\n",
    "\n",
    "\n",
    "class Intent(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Category(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    intents: List[Intent]\n",
    "\n",
    "\n",
    "class Domain(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    categories: List[Category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7506bd2e-ddf3-460e-815b-4f7809063ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. None of these categories match\n",
      "1. Handles tasks related to bank account management.\n",
      "2. Provides information and assistance related to various financial services.\n",
      "3. Provides assistance and resolves issues related to the bank's services.\n",
      "0.0. None of the other intents match, fallback to this intent\n",
      "1.1. The user is looking to open a new bank account.\n",
      "1.2. The user has a query related to logging into their existing bank account.\n",
      "1.3. The user wants to check the amount of money they have in their bank account.\n",
      "1.4. The user is looking to close their existing bank account.\n",
      "1.5. The user is requesting a copy of their bank account statement.\n",
      "1.6. The user has a question or inquiry about a specific transaction on their bank account.\n",
      "1.7. The user wants to update their personal or contact information on their bank account.\n",
      "2.1. The user wants to apply for a new credit card from the bank.\n",
      "2.2. The user wants to exchange one currency for another.\n",
      "2.3. The user is applying for a loan, such as a personal loan, mortgage, or car loan.\n",
      "2.4. The user wants to make a payment on a bill or set up regular payment, such as a utility or credit card bill.\n",
      "2.5. The user wants to speak with a financial advisor for assistance.\n",
      "2.6. The user wants to transfer money or funds.\n",
      "3.1. None of the other intents match, fallback to this intent.\n",
      "3.2. The user is seeking information about the bank's branch.\n",
      "3.3. The user is reporting a lost or stolen bank card and needs assistance.\n",
      "3.4. The user is inquiring about the status of a previous application, such as a loan or account application.\n",
      "3.5. The user is experiencing technical difficulties when trying to pay a bill online or through the bank's system.\n"
     ]
    }
   ],
   "source": [
    "# intents_config = intents_config[0]\n",
    "# pprint(intents_config[0])\n",
    "categories = Domain.model_validate(intents_config[0]).categories\n",
    "# pprint(categories)\n",
    "categories_list = [\"0. None of these categories match\"]\n",
    "\n",
    "intents_config\n",
    "for index, category in enumerate(categories, start=1):\n",
    "    categories_list.append(f\"{index}. {category.description}\")\n",
    "\n",
    "categories_str = \"\\n\".join(categories_list)\n",
    "\n",
    "intent_list = [\"0.0. None of the other intents match, fallback to this intent\"]\n",
    "index_to_intent_map = {\"0.0\": \"Unknown\"}\n",
    "index_to_category_map = {\"0\": \"Unknown\"}\n",
    "for cat_index, category in enumerate(categories, start=1):\n",
    "    index_to_category_map[f\"{cat_index}\"] = category.name\n",
    "    for intent_index, intent in enumerate(category.intents, start=1):\n",
    "        index_to_intent_map[f\"{cat_index}.{intent_index}\"] = intent.name\n",
    "        intent_list.append(f\"{cat_index}.{intent_index}. {intent.description}\")\n",
    "\n",
    "intents_str = \"\\n\".join(intent_list)\n",
    "\n",
    "print(categories_str)\n",
    "print(intents_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f208d197-19da-4b86-94fb-5b85020b7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"example\": itemgetter(\"utterance\") | retriever,  # gets k=2 documents\n",
    "        \"utterance\": itemgetter(\"utterance\"),\n",
    "        \"language_code\": itemgetter(\"language_code\"),\n",
    "        \"categories\": itemgetter(\"categories\"),\n",
    "        \"intents\": itemgetter(\"intents\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\n\\n\", \"Response\", '. '])\n",
    "    | StrOutputParser()\n",
    ")  # .bind(stop=[\"\\n\\n\", \"Response\"])\n",
    "\n",
    "# critique_chain = call_llm_to_do_cot | call_llm_to_label | if_answer is good then done else | critique | label_again\n",
    "# expel_chain = get_insights | get_good_or_bad_examples | call_llm_to_do_cot | call_llm_to_label | if_answer is good then done else | create_insights | label_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a122c7-37ab-49cf-aca7-d348cb64679a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = chain.invoke({\"question\": \"where do a psychologist and detective get lost?\"})\n",
    "# print(response)\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"utterance\": \"need to see all my deposits from the last six months\",\n",
    "        \"language_code\": \"en-US\",\n",
    "        \"categories\": categories_str,\n",
    "        \"intents\": intents_str,\n",
    "    }\n",
    ").strip()\n",
    "\n",
    "print(response)\n",
    "\n",
    "detected_intent = index_to_intent_map[response]\n",
    "# get expected intent\n",
    "# if match then save example to DB.\n",
    "# could also add intents into DB and filter based on example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cdabe6a-0f2a-472b-b792-787b57d3f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.batch([#{\"question\": \"Where do 3 men walk into?\"},\n",
    "#              {\"question\": \"Where do a psychologist and detective get lost?\"},\n",
    "#              {\"question\": \"What did scientist bring back?\"}],\n",
    "#             config={\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fd61d6-ad12-4161-9dc4-8d5620c7aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how custom function can be written to branch execution below.\n",
    "# retriever.add_documents(docs) #Â with see docs above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2134469-27d6-402c-b086-934baa3eca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The provided text does not specify where a psychologist and detective get lost, so I am unable to answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "other_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,  # gets k=2 documents\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind(logprobs=True)\n",
    ")  # | StrOutputParser()\n",
    "msg = other_chain.invoke(\n",
    "    {\"question\": \"where do a psychologist and detective get lost?\"}\n",
    ")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4537bf3-e8bb-48ef-9429-7255654f6ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "target_token_id = tokenizer(\n",
    "    ['2', '1'],\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "type(target_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d42add-157a-47a5-af73-3b3951c31519",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-diss",
   "language": "python",
   "name": "llm-diss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
